%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}
\usepackage{graphicx}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}
\setcounter{tocdepth}{0}



\title{FionaDocs}
\date{Jul 29, 2025}
\release{}
\author{Hauke Bartsch, Marek Kociński}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxAtStartPar
FIONA (Flash\sphinxhyphen{}based Input/Output Network Appliance) \sphinxhyphen{} A secure research data gateway for medical imaging. Provides DICOM anonymization, quarantine management, and automated transfer from clinical to research PACS systems while ensuring GDPR compliance.

\sphinxstepscope


\chapter{LEARN}
\label{\detokenize{EndUser/index:learn}}\label{\detokenize{EndUser/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} Doctors, researchers, medical personnel


\section{1. Project creation, setup and access}
\label{\detokenize{EndUser/index:project-creation-setup-and-access}}
\sphinxAtStartPar
In order to apply for a new project on the research information system (research PACS)
please fill out the application form available under “Apply/Apply for a new research project”
here: \sphinxurl{https://www.google.com} or \sphinxurl{ttps://fiona.medtek.hbe.med.nvsl.no/}.

\sphinxAtStartPar
Additional user access can be requested by the principal investigator of the project under
“Apply/Apply for access to an existing project”.

\sphinxAtStartPar
If you encounter any problems with applying for access, contact \sphinxhref{mailto:Hauke.Bartsch@helse-bergen.no}{Hauke.Bartsch@helse\sphinxhyphen{}bergen.no}.


\section{2. Access to REDCap for structured data}
\label{\detokenize{EndUser/index:access-to-redcap-for-structured-data}}
\sphinxAtStartPar
Our project uses REDCap as an electronic data capture solution. Projects on the research information system can receive access to their REDCap project as well as access to the image data viewing (see next section).


\section{3. Access to the “Sectra DMA Forskning” research PACS viewer}
\label{\detokenize{EndUser/index:access-to-the-sectra-dma-forskning-research-pacs-viewer}}
\sphinxAtStartPar
Access to the image data is provided by IKT. Such access requires a valid Haukeland University Hospital user account and a laptop or PACS workstation that is under control of IKT. If you contact IKT ask for the start menu item “Sectra DMA Forskning”. With the program and your hospital username and password you will gain access to the research picture archive and communication system (PACS).

\sphinxAtStartPar
Without access to a specific research project you will not see any data in the research PACS. Each research projects requires specific permissions to become accessible for a user.

\sphinxAtStartPar
The research PACS viewer is using a separate clinical PACS software installation (Sectra IDS7). In order to prevent possible interactions between the clinical and the research PACS only one of the application can run at a given time. You will be logged out of the clinical PACS if you start the research PACS viewer.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=268\sphinxpxdimen,height=451\sphinxpxdimen]{{ikt-sectra-dma-forskning}.png}
\caption{Forskning PACS start menu icon required to view image data by project.}\label{\detokenize{EndUser/index:id2}}\end{figure}


\section{4. Submit data to the Research Information System}
\label{\detokenize{EndUser/index:submit-data-to-the-research-information-system}}
\sphinxAtStartPar
Overview: The research information system contains two components. Image data is stored in the Sectra DMA Forskning \sphinxhyphen{} an image viewer with a vendor neutral archive (VNA). All meta\sphinxhyphen{}data is stored in table format in an electronic data capture system (REDCap). Sending image data will create the appropriate entries in REDCap. Additional data collection instruments can be set up there and used to capture assessments, consent/assent and results from automated image processing. All image data is assigned to a project to allow for project specific data views for each research information user.

\sphinxAtStartPar
The basic steps to submit data are:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Send DICOM studies to “HBE Fiona” or “Fiona” (modality station)

\item {} 
\sphinxAtStartPar
Assign to project on \sphinxurl{https://fiona.medtek.hbe.med.nvsl.no/applications/Assign/}

\end{enumerate}

\sphinxAtStartPar
In step 1 data arrives in a \sphinxstylestrong{quarantine} location. In step 2 each DICOM study needs to be \sphinxstylestrong{assigned to project}, pseudonymized participant identifier and event name before it will be forwarded to the research PACS and becomes visible to the project users.


\subsection{4.1 Setup of a new project}
\label{\detokenize{EndUser/index:setup-of-a-new-project}}
\sphinxAtStartPar
The project needs to exist on the research information system before participant data is collected. After a successful setup your project and event names should appear in the Assign application.


\subsection{4.2 How to add image data}
\label{\detokenize{EndUser/index:how-to-add-image-data}}
\sphinxAtStartPar
The end\sphinxhyphen{}point for images is FIONA (\sphinxurl{https://fiona.ihelse.no}):
\begin{itemize}
\item {} 
\sphinxAtStartPar
AETitle: FIONA

\item {} 
\sphinxAtStartPar
IP: 10.94.209.30

\item {} 
\sphinxAtStartPar
Port: 11112

\end{itemize}

\sphinxAtStartPar
Images that arrive at this endpoint are added to a quarantine system (FIONA, \sphinxurl{https://fiona.medtek.hbe.med.nvsl.no:4444}) running the REDCap software. Automatic routing rules (stored in REDCap) are used to anonymize and forward the data to the image storage. If such routing has not been set up the “Assign” application (see below) needs to be used to forward individual studies based on pre\sphinxhyphen{}existing patient ID lists.

\sphinxAtStartPar
From Sectra Production you can send image data to the endpoint “HBE Fiona”. Modality stations might also have the “FIONA” endpoint setup. If the data is already anonymized and has a de\sphinxhyphen{}identified PatientName/PatientID entry that indicates the project the FIONA system will attempt to de\sphinxhyphen{}identify (pseudonymization) further DICOM tags and forward the images to IDS7 (may take minutes). No further action is needed. If you suspect this did not work, see the corresponding section about the representation of transfers in REDCap.

\sphinxAtStartPar
Image data that contains patient information cannot be automatically assigned to the appropriate project as there is only a single endpoint for FIONA shared by all projects. To assign participants correctly to projects and de\sphinxhyphen{}identified participant identifiers a user can perform the assignment to project, participant ID and event name in the “Assign” web application.

\sphinxAtStartPar
If the participant identifiers do not exist yet user may add new project specific identifiers in “Assign”. Such identifiers need to follow the naming rules for a project and are verified using regular expression pattern specific for each project.

\sphinxAtStartPar
The web application for the assignment of scans forwarded to HBE Fiona is available at:
\sphinxurl{https://fiona.medtek.hbe.med.nvsl.no/applications/Assign/}

\sphinxAtStartPar
On the Assign website look for your forwarded study. It should appear in about 15 min.
Identify the correct scan using the Accession Number (Undersøkelse\sphinxhyphen{}ID) or the date and time
of the scan. Select your project from the drop\sphinxhyphen{}down. This will fill in the list of patient names
and event names. Select the correct patient name and the event this study belongs to. After
a couple of seconds a new button appears below the study entry. Use it to select and
confirm the assignment. This will forward a de\sphinxhyphen{}identified version of the study data to “Sectra
Forskning”. If you do not assign your data on Assign they will not be forwarded. After a
couple of days (7 days) such data will disappear from the list. Send an email to Hauke to request
a resend.


\subsubsection{4.2.1 Verification steps}
\label{\detokenize{EndUser/index:verification-steps}}
\sphinxAtStartPar
After data arrived at the research PACS a verification step should ensure that all images have been received at the quarantine on FIONA and have been forwarded to research PACS. This can be done by comparing the number of images on the sending station with the number of images in IDS7.

\sphinxAtStartPar
Furthermore the import step will also attempt to de\sphinxhyphen{}identify secondary capture images with burned in image information. This process is fully automated and can result in false positive and occasionally false negative results. After a review of the data in IDS7 the user may decide which secondary image series are “safe” to exclude from the pixel rewriting on import. For example a secondary capture series from DTI may not contain any burned in names or identifying numbers or dates. Such image series can be removed in REDCap from further pixel anonymization.

\sphinxAtStartPar
If the number of images on FIONA does not correspond to the number of images available cache previous assignments and automatically forward such images to the research PACS using the reviously defined project, patient identifier and event name.


\section{5. Export image data from research PACS}
\label{\detokenize{EndUser/index:export-image-data-from-research-pacs}}
\sphinxAtStartPar
Data in the research PACS is secured by generic procedures during data import that delete or rewrite some DICOM tags, changes dates and replaces unique identifiers. A documentation of this process is available on the GitHub repository of the projects for removal of DICOM meta\sphinxhyphen{}tags:
\sphinxurl{https://github.com/mmiv-center/DICOMAnonymizer}, and for the removal of burned in image information: \sphinxurl{https://github.com/mmiv-center/RewritePixel}.

\sphinxAtStartPar
Data stored in the research PACS is therefore in general suited for data sharing IF pseudonymized data is allowed. In order to support users with the task of data pseudonymization the research information system provides the “Review” web application that lists all existing DICOM tags in a research project (\sphinxurl{https://fiona.ihelse.net}).

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Pseudonymized data is defined here as data for which a coupling list exists somewhere in the universe. This is in contrast to anonymized data where such a list does not exist and can also not be created.
\end{sphinxadmonition}

\sphinxAtStartPar
Further de\sphinxhyphen{}identification procedures might require changes to image data such as face stripping, removal of outer ear tissue, cortical folding pattern, etc.. Such potential sources of information for re\sphinxhyphen{}identification have been proposed in the literature but actual attacks based on them have not recently been documented. Better documented and perhaps more relevant are re\sphinxhyphen{}identification using spreadsheet data where external sources are linked to the projects data to discover the supposedly hidden identity of the research participants. For example it might be possible to link Gender, day of birth and the hospital name to a real participant name using a birth or voting registry.


\subsection{5.1 Export using IDS7}
\label{\detokenize{EndUser/index:export-using-ids7}}
\sphinxAtStartPar
The image data from a study can be exported from the research PACS using a right\sphinxhyphen{}click menu entry available in the Informasjonsvindu “Exporter til medium”. Such exports will generate either a derived patient ID \textendash{} if an Anonymization Profile is selected or a faithful copy of the data with all pseudonymized DICOM tags intact.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
This export does not prevent re\sphinxhyphen{}identification. Specifically the PatientID field is created from the pseudonymized ID used in the research PACS and therefore not random.
\end{sphinxadmonition}

\sphinxAtStartPar
The export is also case\sphinxhyphen{}by\sphinxhyphen{}case, which is tedious if many data need to be exported. The export will also result in directory names that do not reflect the research project structure as participant identifier \textendash{} event name \textendash{} modality \textendash{} image series. It may be advantageous to export from IDS7 if a single image study needs to be shared without special requirements. Such export folders will also contain an image viewer.


\subsection{5.2 Export to project specific formats, NIfTI and zip\sphinxhyphen{}files}
\label{\detokenize{EndUser/index:export-to-project-specific-formats-nifti-and-zip-files}}
\sphinxAtStartPar
The research information system supports a separate export facility that is more suited to implement project specific de\sphinxhyphen{}identification. Such export requirements include specific DICOM value changes (replacing underscores with dashes), adding birth date information back, formatting and cleaning of series descriptions, zip\sphinxhyphen{}file exports with specific folder structures etc.. This export is appropriate if the receiving institution has specific requirements on how data should be shared.

\sphinxAtStartPar
Request access to the specialized data exports for your project from \sphinxhref{mailto:Hauke.Bartsch@helse-bergen.no}{Hauke.Bartsch@helse\sphinxhyphen{}bergen.no}. Provide your export specification and we will implement your anonymization scheme and make it available to you and other researchers. As an example the “Export” application currently supports the export in NIfTI formats (using dcm2niix) and the export in several zip\sphinxhyphen{}file formats.


\section{6. Research Information System}
\label{\detokenize{EndUser/index:research-information-system}}
\sphinxAtStartPar
The research information system (RIS) of the Western Norway Health Authorities (Helse\sphinxhyphen{}Vest) also called the “Steve Project” is a secure computer system that stores research data for approved research projects at Haukeland University Hospital and connected hospitals of the Helse Vest region. The project is supported by the radiology department of Haukeland University Hospital and the Mohn Medical Imaging and Visualization Center and approved for research project use by IKT Helse Vest. The physical location of the data is at the premises of IKT Helse Vest Norway. Dedicated storage area and research software (Sectra, IDS7) provides researchers with appropriate permission access to their data. All data is stored in a de\sphinxhyphen{}identified format inside the RIS. Maintaining a coupling list is the responsibility of each project and not part of the functionality of the RIS.

\sphinxAtStartPar
Based on the REK/DIPA rules for each project a lifetime tracking of the research data per project ensures that data can be anonymized based on data sharing requirements, and that data can be deleted at the end of the project phase \sphinxhyphen{} if required. We suggest that research data is allowed to be fully anonymized at the end of the project and remain in RIS for general research access.

\sphinxAtStartPar
Key features of the RIS include:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Hosted side\sphinxhyphen{}by\sphinxhyphen{}side with the clinical PACS as an independent installation.

\item {} 
\sphinxAtStartPar
Accepts de\sphinxhyphen{}identified patient identifiers only.

\item {} 
\sphinxAtStartPar
All data is moved through a de\sphinxhyphen{}identification process upon import into RIS.

\item {} 
\sphinxAtStartPar
All data is assigned to one or more specific research projects and the visibility of data is restricted to individuals with project role access rights.

\item {} 
\sphinxAtStartPar
Projects require a valid REK approval, such documentation has to be provided at the start of a project by the project owner.

\item {} 
\sphinxAtStartPar
The project owner can identify additional user accounts that can access the data.

\item {} 
\sphinxAtStartPar
User access to the research PACS is controlled by IKT and requires a valid Haukeland University Hospital user account.

\end{itemize}

\sphinxstepscope


\chapter{ADMINISTRATION}
\label{\detokenize{ServerAdmin/index:administration}}\label{\detokenize{ServerAdmin/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} IT administrators, DevOps


\section{End\sphinxhyphen{}user contract}
\label{\detokenize{ServerAdmin/index:end-user-contract}}
\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
The following text is from the Apply website for the Steve system. Please check this page for updates to the wording.
\end{sphinxadmonition}

\sphinxAtStartPar
By creating a project on the research information system you agree to the following:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
All data stored in the RIS belongs to the research project owner represented by the PI of the project. Adding and verifying added data to the RIS is the responsibility of the project owner. The RIS team will help research projects to automate this process.

\end{enumerate}

\sphinxAtStartPar
2. Sensitive participant information needs to be stored under a separate account and needs to be accessible to authorized (data\sphinxhyphen{}manager and above) user accounts only. All other research data is stored as de\sphinxhyphen{}identified data (pseudonymized, with external coupling list) or in an anonymized format. This restriction includes sensitive information such as Norwegian identification numbers, real names or parts of real names, other birth certificate information and initials. It is the responsibility of the project to review the result of the de\sphinxhyphen{}identification procedures implemented by the RIS team on image meta\sphinxhyphen{}data using \sphinxurl{https://fiona.medtek.hbe.med.nvsl.no/applications/ReviewDICOMTags} and the result of the detection and removal of burned in image data (IDS7). The project will inform the RIS team in a timely manner if the
pseudonymization procedure of the RIS team needs to be updated. This restriction is in place to allow for the largest possible user base for the RIS including PhD students and external collaborators.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
All research data is stored as part of RIS projects identified by a project name of 5\sphinxhyphen{}20 characters. Users can gain access to the data upon request from the project PI or an appointed representative of the PI.

\item {} 
\sphinxAtStartPar
Projects are expected to utilize best\sphinxhyphen{}practises for data handling such as accounts based on roles like data\sphinxhyphen{}entry (add data only) and data\sphinxhyphen{}manager (change data, export data). Personally identifying fields have to be marked as such (Identifier? field of the instrument designer) and data access groups shall be used for multi\sphinxhyphen{}site project setups.

\item {} 
\sphinxAtStartPar
Projects will undergo a short review from the RIS team before they are moved by the RIS team from development mode into production mode for data capture. This review may generate suggestions for the project on how to implement best practices for longitudinal data captures, missing validation and the use of additional software features. All research data is collected and stored with a valid REK approval for the time period specified in the REK approval. The REK approval is required at the time that the RIS project is created. Any change of the REK approval start and end dates need to be reported to the RIS team. At the end of the project period data can be either: a) deleted or  b) fully anonymized (suggested choice). It is up to the project to inform the RIS team about the correct way of handling the data at the end of the project. By default we will assume that data needs to be deleted. Based on the project end date (REK) the RIS team will inform the PI of the project of a pending change of the project status to the archive state. An archive state project will not allow for further data entry, or changes to captured data. After a period of about 1 year the project data will be exported and provided to the project PI for download. An archived project can be deleted by the RIS team after an unspecified time period. If the project data can be fully anonymized, the RIS team may create a copy of the data with new participant identifiers (without a coupling list). After a re\sphinxhyphen{}import a fully anonymized version of the project data can become accessible to other RIS users. The original project data will change to archive state, a copy is provided to the projects PI and the data can be deleted by the RIS team after about 1 year.

\end{enumerate}


\section{Features for data migration}
\label{\detokenize{ServerAdmin/index:features-for-data-migration}}
\sphinxAtStartPar
The Assign web\sphinxhyphen{}application allows users to upload a coupling list that maps the accession number (Undersøkelse\sphinxhyphen{}ID) of the study to the pseudonymized participant identifier. Such mappings must be uploaded before the first image study of the project has been forwarded to FIONA. Incoming DICOM studies in FIONA that match entries in the coupling list will automatically be assigned to the project.


\section{How to handle errors?}
\label{\detokenize{ServerAdmin/index:how-to-handle-errors}}
\sphinxAtStartPar
Correcting errors during data import are not difficult to fix. Try to follow up on such errors on an ongoing basis. The quarantine FIONA station may have still have a copy of the data in its cache which simplifies the process. Contact \sphinxhref{mailto:Hauke.Bartsch@helse-bergen.no}{Hauke.Bartsch@helse\sphinxhyphen{}bergen.no} in such cases and ask for help. This will allow you to fix issues such as:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Wrong assignment of participant identifiers to DICOM studies

\item {} 
\sphinxAtStartPar
Wrong assignment of event names to DICOM studies

\item {} 
\sphinxAtStartPar
Missing images or image series for existing DICOM studies

\item {} 
\sphinxAtStartPar
Missing entries for DICOM studies on “Assign”

\end{itemize}


\section{Export to project specific formats, NIfTI and zip\sphinxhyphen{}files}
\label{\detokenize{ServerAdmin/index:export-to-project-specific-formats-nifti-and-zip-files}}
\sphinxAtStartPar
The research information system supports a separate export facility that is more suited to implement project specific de\sphinxhyphen{}identification. Such export requirements include specific DICOM value changes (replacing underscores with dashes), adding birth date information back, formatting and cleaning of series descriptions, zip\sphinxhyphen{}file exports with specific folder structures etc.. This export is appropriate if the receiving institution has specific requirements on how data should be shared.

\sphinxAtStartPar
Request access to the specialized data exports for your project from \sphinxhref{mailto:Hauke.Bartsch@helse-bergen.no}{Hauke.Bartsch@helse\sphinxhyphen{}bergen.no}. Provide your export specification and we will implement your anonymization scheme and make it available to you and other researchers. As an example the “Export” application currently supports the export in NIfTI formats (using dcm2niix) and the export in several zip\sphinxhyphen{}file formats.


\section{Sensitive Data Projects \textendash{} Separation of Sensitive Information and Data}
\label{\detokenize{ServerAdmin/index:sensitive-data-projects-separation-of-sensitive-information-and-data}}
\sphinxAtStartPar
A sensitive data project is one that is used to capture human subject data and in general will require a REK (regional ethics board approval). In order to setup such a project in REDCap we suggest the follow structure and features of REDCap to be used. These recommendations have been generated based on discussions in relevant risk assessments.

\sphinxAtStartPar
All sensitive data should be stored in a separate REDCap “ID” project including Norwegian Identification Numbers, names or parts of names, addresses and full birth dates (see Figure 1). This project should have its own roles of “Data Manager”, “Data Entry”, and “Controller”.  eople with permission to access and/or edit this information can use this database to keep contact information up\sphinxhyphen{}to\sphinxhyphen{}date and to enroll new participants into the study. Each participant should be assigned a pseudonymized ID in the sensitive data project that links the entry to the corresponding participant in the data project. Examples for this ID are: \textless{}project name\textgreater{}\sphinxhyphen{}\textless{}site number\textgreater{}\sphinxhyphen{}0001, \textless{}project name\textgreater{}\sphinxhyphen{}\textless{}site number\textgreater{}\sphinxhyphen{}0002, etc..

\sphinxAtStartPar
All other data should be stored in a separate REDCap “Data” project using the pseudonymized participant ID as a “record\_id” (first field in the study).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{redcap-sensitive-data}.png}
\caption{Sensitive data projects should be split into a REDCap project for data (using pseudonymized ids) and a REDCap project for sensitive data including the coupling list.}\label{\detokenize{ServerAdmin/index:id1}}\end{figure}


\subsection{User rights management}
\label{\detokenize{ServerAdmin/index:user-rights-management}}
\sphinxAtStartPar
When a project leader / principal investigator (PI) is given a REDCap account and project, they are given “project owner” roles. The project owner can then provide access to project members in “roles”. A role defines a given set of custom permissions which defines the user’s access to data, export permissions and ability to make changes to data.

\sphinxAtStartPar
Each project can have predefined roles. We recommend the predefined roles “Data Manager” (ability to change study design, export), “Data Entry” (add, change, or delete data) and “Controller” to define roles for data viewing, editing, and deleting records. In more complex cases, different access settings can be given on different forms in the study (see also API access with REDCap). Individual users are assigned to project roles as part of gaining access to one project.

\sphinxAtStartPar
The user rights management is the responsibility of the project owner and/or the users they add to the project with User Rights access. User roles should be set at the lowest access level that is necessary (e.g., export rights only for users who need this permission). Access to the project should be reviewed regularly and personnel who no longer require access need to be removed from the project.


\subsection{User rights \textendash{} multi\sphinxhyphen{}center projects}
\label{\detokenize{ServerAdmin/index:user-rights-multi-center-projects}}
\sphinxAtStartPar
In a project where several institutions participate with their own project participants (several hospitals etc.) each group of participants should be assigned to a separate “data access group”. This functionality allows records in a study to be part of the user rights management. A user with access to a single data access group can only see participants that belong to this group. If this user creates a new participant, they will be automatically assigned to the group.


\subsection{How to handle Email Addresses in Data Projects}
\label{\detokenize{ServerAdmin/index:how-to-handle-email-addresses-in-data-projects}}
\sphinxAtStartPar
Email addresses are special identifying fields that can be stored in data projects for the purpose of creating automated invites for participants to fill out forms from home. In projects that use this feature email fields need to be present in the data project in order to allow for email distribution to participants.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Add such email fields to a separate instrument of the REDCap data project and mark the instrument as viewable by specific roles only (like Data Managers).

\item {} 
\sphinxAtStartPar
Mark the email field as an “Identifier” field to prevent export of the field’s data by user  of roles that cannot view sensitive fields.

\item {} 
\sphinxAtStartPar
Add the Action Tag “@PASSWORDMASK” to the field to prevent accidental viewing of the fields values if the instrument is displayed on screen.

\item {} 
\sphinxAtStartPar
Add a field validation as “Email” to prevent some miss\sphinxhyphen{}typing of emails.

\end{enumerate}


\subsection{Automatic data exports from REDCap}
\label{\detokenize{ServerAdmin/index:automatic-data-exports-from-redcap}}
\sphinxAtStartPar
Data may be exported from REDCap using the REDCap API, a technical interface to automate the export of project and participant information using scripting. To provide such access a dedicated user\sphinxhyphen{}account “api\_\textless{}real username\textgreater{}” should be created which is specific for a single project. Configure the account with a limited set of read permissions to specific fields or instruments using a new API role. The REDCap API will borrow these restrictive permissions for controlled access.

\sphinxAtStartPar
Setup: An administrator can generate an API “token” for this account and share the token and examples of accessing the resource (curl\sphinxhyphen{}based access) with the user.

\sphinxAtStartPar
Any change in the role of the \textless{}real username\textgreater{} should also apply to the connected API account. Specifically loosing access to the project should be implemented for both \textless{}real username\textgreater{} and api\_\textless{}real username\textgreater{}.


\subsection{Steps at the end of a REDCap project}
\label{\detokenize{ServerAdmin/index:steps-at-the-end-of-a-redcap-project}}
\sphinxAtStartPar
REDCap is a tool for data collection. At the end of data capture projects using REDCap receive a notification of study end. At this point projects may provide updated REK information(extension of data capture notice). If no such notice is received REDCap projects will:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Lock all data participants (no further update/add).

\item {} 
\sphinxAtStartPar
Provide a copy of the REDCap project (CDISC format) to the project’s principal investigator or delegate.

\item {} 
\sphinxAtStartPar
Provide a copy of the project data (CSV) and data dictionary (PDF) to the principal investigator or delegate.

\item {} 
\sphinxAtStartPar
Request a confirmation that project data (CDISC and CSV) have been received by the project.

\item {} 
\sphinxAtStartPar
Permanently delete all project data.

\end{itemize}

\sphinxAtStartPar
This process will be documented in the REDCap project tracking project “DataTransferProjects”, the project management tool with information on identity of the person requesting project removal and confirmations for all steps of the project removal process.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{redcap-end-of-project}.png}
\caption{End\sphinxhyphen{}of\sphinxhyphen{}project tracking for REDCap projects}\label{\detokenize{ServerAdmin/index:id2}}\end{figure}

\sphinxstepscope


\chapter{ARCHITECTURE}
\label{\detokenize{Architecture/index:architecture}}\label{\detokenize{Architecture/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} Developers, system architects


\section{Overview}
\label{\detokenize{Architecture/index:overview}}
\sphinxAtStartPar
The architecture of Fiona sysetem can be included included into a few layers: network layer, processing layer, storage layer, transfer layer and management layer

\sphinxincludegraphics{mermaid-4988ce419744bfb9f969fef2cdd72d109cda4494.pdf}


\section{System Purpose}
\label{\detokenize{Architecture/index:system-purpose}}
\sphinxAtStartPar
FIONA serves as an intermediary system that:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Receives medical image data from clinical PACS systems

\item {} 
\sphinxAtStartPar
Processes and classifies incoming DICOM studies

\item {} 
\sphinxAtStartPar
Anonymizes data according to research requirements

\item {} 
\sphinxAtStartPar
Manages data transfer back to research PACS systems

\item {} 
\sphinxAtStartPar
Provides project\sphinxhyphen{}specific data organization

\end{itemize}


\section{Data Storage Structure}
\label{\detokenize{Architecture/index:data-storage-structure}}
\sphinxAtStartPar
The FIONA system uses a hierarchical storage structure:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/data/
├── site/
│   ├── .arrived/          \PYGZsh{} Initial file reception
│   ├── archive/           \PYGZsh{} Raw DICOM storage
│   ├── raw/              \PYGZsh{} Processed DICOM files
│   └── output/           \PYGZsh{} Processing results
├── config/               \PYGZsh{} Configuration files
└── logs/                 \PYGZsh{} System logs
\end{sphinxVerbatim}

\sphinxAtStartPar
Project\sphinxhyphen{}specific directories follow the pattern:
/data\{PROJECT\}/site/…


\section{Data Flow}
\label{\detokenize{Architecture/index:data-flow}}
\sphinxAtStartPar
This document describes the complete data flow through the FIONA system, from initial DICOM reception to final transfer to research PACS.

\sphinxAtStartPar
Data flow overwie (ver.1 \sphinxhyphen{} detailed)

\sphinxincludegraphics{mermaid-12fc7085419961f463017bf9f9db05921e8f031b.pdf}


\section{Folder and File structure}
\label{\detokenize{Architecture/index:folder-and-file-structure}}


\sphinxstepscope


\subsection{anonymizeAndSend.py}
\label{\detokenize{Architecture/scripts/anonymizeAndSend:anonymizeandsend-py}}\label{\detokenize{Architecture/scripts/anonymizeAndSend::doc}}
\sphinxAtStartPar
There is no docstring.

\sphinxAtStartPar
2025.06.17 mk

\sphinxstepscope


\subsection{clearExports.sh}
\label{\detokenize{Architecture/scripts/clearExports:clearexports-sh}}\label{\detokenize{Architecture/scripts/clearExports::doc}}
\sphinxAtStartPar
find . \sphinxhyphen{}type d \sphinxhyphen{}maxdepth 1 \sphinxhyphen{}printf ‘\%T+ “\%p”n’ | sort | less

\sphinxAtStartPar
delete oldest files until we have at least 20\% free space on this partition

\sphinxstepscope


\subsection{clearOldFiles.sh}
\label{\detokenize{Architecture/scripts/clearOldFiles:clearoldfiles-sh}}\label{\detokenize{Architecture/scripts/clearOldFiles::doc}}
\sphinxAtStartPar
find . \sphinxhyphen{}type d \sphinxhyphen{}maxdepth 1 \sphinxhyphen{}printf ‘\%T+ “\%p”n’ | sort | less

\sphinxAtStartPar
delete oldest files until we have at least 20\% free space on this partition

\sphinxAtStartPar
TODO: delete links in /data/site/participants/

\sphinxAtStartPar
TODO: delete links in /data/site/srs/

\sphinxstepscope


\subsection{clearStaleLinks.sh}
\label{\detokenize{Architecture/scripts/clearStaleLinks:clearstalelinks-sh}}\label{\detokenize{Architecture/scripts/clearStaleLinks::doc}}
\sphinxAtStartPar
Delete links that do not point to real images in archive.

\sphinxAtStartPar
Just to be sure we have a clear /data/site/raw folder we should remove broken symbolic link and empty folders.

\sphinxstepscope


\subsection{createTransferRequestProcessed.py}
\label{\detokenize{Architecture/scripts/createTransferRequestForProcessed:createtransferrequestprocessed-py}}\label{\detokenize{Architecture/scripts/createTransferRequestForProcessed::doc}}
\sphinxAtStartPar
There is no docstring.

\sphinxstepscope


\subsection{createTransferRequest.py}
\label{\detokenize{Architecture/scripts/createTransferRequest:createtransferrequest-py}}\label{\detokenize{Architecture/scripts/createTransferRequest::doc}}
\sphinxAtStartPar
There is no docstring.

\sphinxstepscope


\subsection{createZipFileCmd.php}
\label{\detokenize{Architecture/scripts/createZipFileCmd:createzipfilecmd-php}}\label{\detokenize{Architecture/scripts/createZipFileCmd::doc}}
\sphinxAtStartPar
This is a docstring.

\sphinxstepscope


\subsection{cron.sh}
\label{\detokenize{Architecture/scripts/cron:cron-sh}}\label{\detokenize{Architecture/scripts/cron::doc}}
\sphinxAtStartPar
There is no docstring.

\sphinxstepscope


\subsection{detectStudyArrival}
\label{\detokenize{Architecture/scripts/detectStudyArrival:detectstudyarrival}}\label{\detokenize{Architecture/scripts/detectStudyArrival::doc}}
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{detectStudyArrival.sh}} monitors and processes incoming DICOM study arrivals in a medical imaging pipeline. The script checks for new study jobs created by receiveSingleFile.sh, processes them after a configurable delay, and triggers various quality control and compliance checks.

\sphinxAtStartPar
\sphinxstylestrong{The Main Dependences:}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxstylestrong{user:} none
\item[] \sphinxhyphen{} \sphinxstylestrong{depends\sphinxhyphen{}on:}
\item[]
\begin{DUlineblock}{\DUlineblockindent}
\item[] \sphinxhyphen{} receiveSingleFile.sh
\item[] \sphinxhyphen{} anonymize.sh
\item[] \sphinxhyphen{} /data/config/config.json
\item[] \sphinxhyphen{} /tmp/.processSingleFilePipe
\item[] \sphinxhyphen{} /var/www/html/applications/Assign/incoming.txt
\end{DUlineblock}
\item[] \sphinxhyphen{} \sphinxstylestrong{log\sphinxhyphen{}file:}
\item[]
\begin{DUlineblock}{\DUlineblockindent}
\item[] \sphinxhyphen{} \$\{SERVERDIR\}/logs/detectStudyArrival.log
\item[] \sphinxhyphen{} SERVERDIR/logs/detectStudyArrival\{SERVERDIR\}/logs/detectStudyArrival
\item[] \sphinxhyphen{} SERVERDIR/logs/detectStudyArrival\{projname\}.log
\end{DUlineblock}
\item[] \sphinxhyphen{} \sphinxstylestrong{pid\sphinxhyphen{}file:}
\item[]
\begin{DUlineblock}{\DUlineblockindent}
\item[] \sphinxhyphen{} SERVERDIR/.pids/detectStudyArrival\{SERVERDIR\}/.pids/detectStudyArrival
\item[] \sphinxhyphen{} SERVERDIR/.pids/detectStudyArrival\{projname\}.lock
\end{DUlineblock}
\item[] \sphinxhyphen{} \sphinxstylestrong{start:}
\item[]
\begin{DUlineblock}{\DUlineblockindent}
\item[] \sphinxhyphen{} ./detectStudyArrival.sh
\item[] \sphinxhyphen{} ./detectStudyArrival.sh {[}PROJECT\_NAME{]}
\end{DUlineblock}
\item[] \sphinxhyphen{} \sphinxstylestrong{license:} TBE
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{cron Configuration}

\sphinxAtStartPar
The script is designed to run via cron every 15 seconds to detect new arrivals and process studies for both ABCD and PCGC projects.
Add these lines to crontab \sphinxhyphen{}e for 15\sphinxhyphen{}second monitoring intervals:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
*/1 * * * * /data/code/bin/detectStudyArrival.sh
*/1 * * * * sleep 15; /data/code/bin/detectStudyArrival.sh
*/1 * * * * sleep 30; /data/code/bin/detectStudyArrival.sh
*/1 * * * * sleep 45; /data/code/bin/detectStudyArrival.sh
\end{sphinxVerbatim}

\sphinxAtStartPar
For PCGC project:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
*/1 * * * * /data/code/bin/detectStudyArrival.sh PCGC
*/1 * * * * sleep 15; /data/code/bin/detectStudyArrival.sh PCGC
*/1 * * * * sleep 30; /data/code/bin/detectStudyArrival.sh PCGC
*/1 * * * * sleep 45; /data/code/bin/detectStudyArrival.sh PCGC
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Input/Output File Dependencies Diagram}

\sphinxincludegraphics{mermaid-6a07ace84f13e3725b6bcc6d1d30aa8df307effe.pdf}

\sphinxAtStartPar
\sphinxstylestrong{File Descriptions:}
| 1. Input Files:

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data/config/config.json}} \sphinxhyphen{} Main configuration file with project settings
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data/site/.arrived/*}} \sphinxhyphen{} Job files containing study arrival information
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{receiveSingleFile.sh}} \sphinxhyphen{} Script creating study arrival job files
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] 2. Output Files:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/tmp/.processSingleFilePipe}} \sphinxhyphen{} Named pipe for queuing files to process
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/var/www/html/applications/Assign/incoming.txt}} \sphinxhyphen{} Web interface assignment list for studies
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{logs/detectStudyArrival.log}} \sphinxhyphen{} Log file recording processing activities
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{pids/detectStudyArrival.lock}} \sphinxhyphen{} Lock file preventing concurrent execution
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{quarantine/*.tgz}} \sphinxhyphen{} Compressed archive files of processed data
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{quarantine/*.md5sum}} \sphinxhyphen{} Checksum files for data integrity verification
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] 3. Scripts:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{detectStudyArrival.sh}} \sphinxhyphen{} Main script monitoring DICOM study arrivals
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{anonymize.sh}} \sphinxhyphen{} Script for anonymizing DICOM files
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{Data Flow Dependencies}

\sphinxincludegraphics{mermaid-4b5690ac216ff64ef341c2900c193f60650de046.pdf}

\sphinxAtStartPar
\sphinxstylestrong{Data Flow File Descriptions:}

\begin{DUlineblock}{0em}
\item[] 1. Input Files:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{site/raw/SDIR/SSERIESDIR/}} \sphinxhyphen{} Directory containing raw DICOM files
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{site/raw/SDIR/SSERIESDIR.json}} \sphinxhyphen{} Metadata file with series information
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{PFILEDIR/}} \sphinxhyphen{} Directory for packed files storage
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] 2. Output Files:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{site/archive/SDIR/}} \sphinxhyphen{} Archive directory for processed studies
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{site/output/SDIR/}} \sphinxhyphen{} Output directory for QC reports
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{quarantine/}} \sphinxhyphen{} Directory for quarantined data
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] 3. Scripts:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{detectStudyArrival.sh}} \sphinxhyphen{} Main script processing data flow
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] 4. Docker Containers:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} Docker: \sphinxcode{\sphinxupquote{ABCDPhantomQC}} \sphinxhyphen{} Container for phantom quality control
\item[] \sphinxhyphen{} Docker: \sphinxcode{\sphinxupquote{compliance\_check}} \sphinxhyphen{} Container for protocol compliance
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{Directories:}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data/site/.arrived/}} \sphinxhyphen{} Job arrival directory (ABCD)
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data{[}PROJECT{]}/site/.arrived/}} \sphinxhyphen{} Project\sphinxhyphen{}specific arrival directories
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{DATADIR\}/site/raw/}} \sphinxhyphen{} Raw DICOM storage
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{DATADIR\}/site/archive/}} \sphinxhyphen{} Archived studies
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{DATADIR\}/site/output/}} \sphinxhyphen{} Processing results
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{DATADIR\}/quarantine/}} \sphinxhyphen{} Quarantine storage
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{PFILEDIR\}/}} \sphinxhyphen{} Packed file directory
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{SERVERDIR\}/logs/}} \sphinxhyphen{} Log file location
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{SERVERDIR\}/.pids/}} \sphinxhyphen{} Lock file directory
\end{DUlineblock}


\subsubsection{detectStudyArrival.sh}
\label{\detokenize{Architecture/scripts/detectStudyArrival:detectstudyarrival-sh}}
\sphinxAtStartPar
check the study job directory created by receiveSingleFile.sh

\sphinxAtStartPar
if the file is old enough process it using the information provided

\sphinxAtStartPar
Add this to “crontab \sphinxhyphen{}e” to check every 15 seconds if a new job arrived.
\sphinxcode{\sphinxupquote{*/1 * * * * /data/code/bin/detectStudyArrival.sh}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 30; /data/code/bin/detectStudyArrival.sh}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 15; /data/code/bin/detectStudyArrival.sh}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 45; /data/code/bin/detectStudyArrival.sh}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * /data/code/bin/detectStudyArrival.sh PCGC}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 30; /data/code/bin/detectStudyArrival.sh PCGC}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 15; /data/code/bin/detectStudyArrival.sh PCGC}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 45; /data/code/bin/detectStudyArrival.sh PCGC}}

\sphinxstepscope


\subsection{getAllPatients2.sh}
\label{\detokenize{Architecture/scripts/getAllPatients2:getallpatients2-sh}}\label{\detokenize{Architecture/scripts/getAllPatients2::doc}}
\sphinxAtStartPar
We can provide an argument to this program, the maximum number of days we would like to pull. In general we might get away with a very short
period because new scans will come in as recent scans. But some test data migth be very old. So we should do one long run at night and short
runs during the day.

\sphinxAtStartPar
As a second argument allow a specific project name. The whole things takes too long right now. Treat some project as special here.

\sphinxstepscope


\subsection{heartbeat.sh}
\label{\detokenize{Architecture/scripts/heartbeat:heartbeat-sh}}\label{\detokenize{Architecture/scripts/heartbeat::doc}}
\sphinxAtStartPar
create a heart beat for the storescp

\sphinxAtStartPar
One way it can fail is if multiple associations are requested.

\sphinxAtStartPar
If the timeout happens the connection will be unusable afterwards.

\sphinxAtStartPar
Here we simply use echoscu to test the connection and if that fails we will kill a running storescp (hoping that monit will start it again).

\sphinxAtStartPar
In order to activate put this into the crontab of processing (every minute):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
*/1 * * * * /usr/bin/nice \PYGZhy{}n 3 /var/www/html/server/bin/heartbeat.sh
\end{sphinxVerbatim}

\sphinxstepscope


\subsection{moveFromScanner.sh}
\label{\detokenize{Architecture/scripts/moveFromScanner:movefromscanner-sh}}\label{\detokenize{Architecture/scripts/moveFromScanner::doc}}
\sphinxAtStartPar
Called from cron\sphinxhyphen{}job, checks the study data in /dataPCGC/active\sphinxhyphen{}scans for things to pull from the scanner.

\sphinxAtStartPar
If all images are already found (only checks number of images) the series will not be pulled again.
If all images of all series are present on the system the /dataPCGC/active\sphinxhyphen{}scans/\textless{}StudyInstanceUID\textgreater{} file is copied to the /dataPCGC/finished\sphinxhyphen{}scans/ folder.

\sphinxAtStartPar
This script will only run if there is no “/var/www/html/server/.pids/moveFromScannerPCGC.lock”. This prevents multiple executions of this script in cases that a single processing steps takes more than 15 seconds.

\sphinxAtStartPar
This script will only run if there is no “0” in the second /dataPCGC/enabled bin (like in “101”).

\sphinxAtStartPar
This script depends on the following dcmtk tools: dcm2dump, findscu, movescu.

\sphinxAtStartPar
Install using a cron\sphinxhyphen{}job every 15 seconds

\begin{sphinxVerbatim}[commandchars=\\\{\}]
*/1 * * * * /var/www/html/server/bin/moveFromScanner.sh
*/1 * * * * sleep 30; /var/www/html/server/bin/moveFromScanner.sh
*/1 * * * * sleep 15; /var/www/html/server/bin/moveFromScanner.sh
*/1 * * * * sleep 45; /var/www/html/server/bin/moveFromScanner.sh
*/1 * * * * /var/www/html/server/bin/moveFromScanner.sh PCGC
*/1 * * * * sleep 30; /var/www/html/server/bin/moveFromScanner.sh PCGC
*/1 * * * * sleep 15; /var/www/html/server/bin/moveFromScanner.sh PCGC
*/1 * * * * sleep 45; /var/www/html/server/bin/moveFromScanner.sh PCGC
\end{sphinxVerbatim}

\sphinxstepscope


\subsection{mppsctl.sh}
\label{\detokenize{Architecture/scripts/mppsctl:mppsctl-sh}}\label{\detokenize{Architecture/scripts/mppsctl::doc}}
\sphinxAtStartPar
filename: ppsscpfs
\begin{description}
\sphinxlineitem{purpose:}\begin{itemize}
\item {} 
\sphinxAtStartPar
start DICOM multiple performed procedure steps server

\item {} 
\sphinxAtStartPar
Keeps track of scans on the server:

\end{itemize}

\end{description}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
*/1 * * * * /var/www/html/server/bin/mppsctl.sh start
\end{sphinxVerbatim}

\sphinxAtStartPar
(Hauke Bartsch)

\sphinxstepscope


\subsection{parseAllPatients.sh}
\label{\detokenize{Architecture/scripts/parseAllPatients:parseallpatients-sh}}\label{\detokenize{Architecture/scripts/parseAllPatients::doc}}
\sphinxAtStartPar
depends on output generated by getAllPatients2.sh

\sphinxAtStartPar
get list of optional findscu entries from \sphinxurl{http://dicom.nema.org/medical/dicom/current/output/html/part04.html\#sect\_C.6.1.1}

\sphinxstepscope


\subsection{populateAutoID.py}
\label{\detokenize{Architecture/scripts/populateAutoID:populateautoid-py}}\label{\detokenize{Architecture/scripts/populateAutoID::doc}}
\sphinxAtStartPar
Check all auto\sphinxhyphen{}id projects and create new transfer requests for each

\sphinxstepscope


\subsection{populateIncoming.py}
\label{\detokenize{Architecture/scripts/populateIncoming:populateincoming-py}}\label{\detokenize{Architecture/scripts/populateIncoming::doc}}
\sphinxAtStartPar
This program fills in the Study and Series information in the Incoming table in REDCap.

\sphinxAtStartPar
If a CouplingList entry exists its also adding a TransferRequest so that anonymizeAndSend can do its job.

\sphinxAtStartPar
TODO: support a new CouplingList entry even if there is already a TransferRequest done.

\sphinxstepscope


\subsection{populateProjects.py}
\label{\detokenize{Architecture/scripts/populateProjects:populateprojects-py}}\label{\detokenize{Architecture/scripts/populateProjects::doc}}
\sphinxAtStartPar
Each study that has been forwarded to PACS should appear in its own REDCap project.

\sphinxAtStartPar
We can get a list of all transferred studies from incomings transfers. We get a token for the project and add the entry \sphinxhyphen{} if it does not exist yet.

\sphinxAtStartPar
For informatino to appear in the Imaging instrument you need to set it up as a repeating instrument for “Event 1” (not a repeating event!).

\sphinxAtStartPar
TODO: Without calling for specific projects does not work anymore. We need to get a list of all imaging projects and run them project by project.

\sphinxstepscope


\subsection{processSingleFile3.py}
\label{\detokenize{Architecture/scripts/processSingleFile3:processsinglefile3-py}}\label{\detokenize{Architecture/scripts/processSingleFile3::doc}}
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{processSingleFile3.py}} is a Python daemon process that monitors DICOM files, extracts header information, and creates Study/Series symbolic link structures. The script implements a generic daemon class and a specialized DICOM processing class that listens for incoming messages via named pipes, processes DICOM files, and organizes them into a structured directory hierarchy.

\sphinxAtStartPar
\sphinxstylestrong{The Main Dependences}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxstylestrong{user:}
\item[] \sphinxhyphen{} \sphinxstylestrong{depends\sphinxhyphen{}on:}
\item[] \sphinxhyphen{} \sphinxstylestrong{log\sphinxhyphen{}file:} /../logs/processSingleFile{[}projname{]}.log
\item[] \sphinxhyphen{} \sphinxstylestrong{pid\sphinxhyphen{}file:}
\item[]
\begin{DUlineblock}{\DUlineblockindent}
\item[] \sphinxhyphen{}        /../.pids/processSingleFile{[}projname{]}.pid
\item[] \sphinxhyphen{}       /tmp/processSingleFile{[}projname{]}.pid
\end{DUlineblock}
\item[] \sphinxhyphen{} \sphinxstylestrong{start:} python processSingleFile3.py start {[}projname{]}
\item[] \sphinxhyphen{} \sphinxstylestrong{license:} Tbe
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{The processing workflow:}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} Receives file paths via named pipe
\item[] \sphinxhyphen{} Reads DICOM files and extracts metadata
\item[] \sphinxhyphen{} Parses Siemens CSA headers for additional information
\item[] \sphinxhyphen{} Applies classification rules from classifyRules.json
\item[] \sphinxhyphen{} Creates organized directory structure with symbolic links
\item[] \sphinxhyphen{} Generates JSON metadata files for each series
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{Input/Output File Dependencies Diagram}

\sphinxincludegraphics{mermaid-471345e5fef0fa730e81db312082dddc555c9426.pdf}

\sphinxAtStartPar
\sphinxstylestrong{File Description:}

\begin{DUlineblock}{0em}
\item[] 1. Input Files:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{config.json}} \sphinxhyphen{} project configuration and directory paths
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{classifyRules.json}} \sphinxhyphen{} DICOM series classification rules
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{named pipe}} \sphinxhyphen{} daemon communication, receives file paths
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{DICOM files}} \sphinxhyphen{} medical imaging files to be processed
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] 2. Output Files:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{*.pid}} \sphinxhyphen{} daemon process ID
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{*.log}} \sphinxhyphen{} operation and error logs
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{*.json metadata}} \sphinxhyphen{} series metadata in JSON format
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{symbolic links}} \sphinxhyphen{} links to original DICOM files
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{organized directories}} \sphinxhyphen{} directory structure organized by patients/studies
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{Data Flow Dependencies}

\sphinxincludegraphics{mermaid-39ec4fbe90e5a768b173f38604f4994a833cb136.pdf}

\sphinxAtStartPar
\sphinxstylestrong{Data Flow components:}

\begin{DUlineblock}{0em}
\item[] 1. Input Files:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{config.json}} \sphinxhyphen{} system configuration file containing project settings and directory paths
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{classifyRules.json}} \sphinxhyphen{} rule definitions for automatic DICOM series classification
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{named pipe}} \sphinxhyphen{} inter\sphinxhyphen{}process communication channel receiving file processing commands
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{DICOM files}} \sphinxhyphen{} medical imaging files in DICOM format containing patient data
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] 2. Main Process:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{processSingleFile3.py}} \sphinxhyphen{} daemon process that orchestrates DICOM file processing and organization
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] 3. Output Files:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{*.pid}} \sphinxhyphen{} process identifier files for daemon management and monitoring
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{*.log}} \sphinxhyphen{} log files containing operational messages and error reports
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{*.json}} \sphinxhyphen{} metadata files with extracted DICOM header information
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{symbolic links}} \sphinxhyphen{} file system links organizing DICOM files by study structure
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{organized directories}} \sphinxhyphen{} hierarchical directory structure arranged by patients and studies
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{Directories:}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data}} \sphinxhyphen{} Default data directory
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data/site/.arrived}} \sphinxhyphen{} Touch files for series arrival detection
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data/site/participants}} \sphinxhyphen{} Patient\sphinxhyphen{}organized directory structure
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data/site/srs}} \sphinxhyphen{} Structured reports directory
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data/site/raw}} \sphinxhyphen{} Raw DICOM files organized by Study/Series
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data/site/temp}} \sphinxhyphen{} Temporary files directory
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{../logs/}} \sphinxhyphen{} Log files directory
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{../.pids/}} \sphinxhyphen{} Process ID files directory
\end{DUlineblock}


\subsubsection{processSingleFile3.py}
\label{\detokenize{Architecture/scripts/processSingleFile3:id1}}
\sphinxAtStartPar
Create a daemon process that listens to send messages and reads a DICOM file,
extracts the header information and creates a Study/Series symbolic link structure.
\begin{description}
\sphinxlineitem{The parser for the Siemens CSA header have been adapted from}
\sphinxAtStartPar
\sphinxurl{https://scion.duhs.duke.edu/svn/vespa/tags/0\_1\_0/libduke\_mr/util\_dicom\_siemens.py}

\end{description}

\sphinxstepscope


\subsection{process\_tiff.sh}
\label{\detokenize{Architecture/scripts/process_tiff:process-tiff-sh}}\label{\detokenize{Architecture/scripts/process_tiff::doc}}
\sphinxAtStartPar
To be updated.

\sphinxstepscope


\subsection{removeOldEntries.sh}
\label{\detokenize{Architecture/scripts/removeOldEntries:removeoldentries-sh}}\label{\detokenize{Architecture/scripts/removeOldEntries::doc}}
\sphinxAtStartPar
Rremove any old entries from incoming.txt

\sphinxstepscope


\subsection{resendProject.py}
\label{\detokenize{Architecture/scripts/resendProject:resendproject-py}}\label{\detokenize{Architecture/scripts/resendProject::doc}}
\sphinxAtStartPar
check all transfer requests that have already been done

\sphinxAtStartPar
if the send date is before the request date send again

\sphinxstepscope


\subsection{runOneJob.sh}
\label{\detokenize{Architecture/scripts/runOneJob:runonejob-sh}}\label{\detokenize{Architecture/scripts/runOneJob::doc}}
\sphinxAtStartPar
Run a single job from the workflow\_joblist.jobs file. The file contains json code per line.

\sphinxAtStartPar
Need to run as user “processing” with flock.
\begin{description}
\sphinxlineitem{Example cron job:}\begin{description}
\sphinxlineitem{/usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/Workflows\_RunOneJob.pid }
\sphinxAtStartPar
/var/www/html/applications/Workflows/php/runOneJob.sh \textgreater{}\textgreater{} /home/processing/logs/Workflows\_RunOneJob.log 2\textgreater{}\&1

\end{description}

\end{description}

\sphinxstepscope


\subsection{sendFiles.sh}
\label{\detokenize{Architecture/scripts/sendFiles:sendfiles-sh}}\label{\detokenize{Architecture/scripts/sendFiles::doc}}
\sphinxAtStartPar
Example crontab entry that starts this script every 30 minutes

\begin{sphinxVerbatim}[commandchars=\\\{\}]
*/30 * * * * /usr/bin/nice \PYGZhy{}n 3 /var/www/html/server/bin/sendFiles.sh
\end{sphinxVerbatim}

\sphinxAtStartPar
Add the above line to your machine using:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZgt{}\PYG{+w}{ }crontab\PYG{+w}{ }\PYGZhy{}e
\end{sphinxVerbatim}

\sphinxAtStartPar
This script is supposed to send compressed data files for DICOM and k\sphinxhyphen{}space to the DAIC endpoint using sftp. All data in the /data/outbox directory will be send using local and DAIC md5sum files.

\sphinxstepscope


\subsection{storectl.sh}
\label{\detokenize{Architecture/scripts/storectl:storectl-sh}}\label{\detokenize{Architecture/scripts/storectl::doc}}
\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{storectl.sh}} script is a system service controller for managing DICOM storage operations. It starts/stops the storescpFIONA daemon which receives DICOM files over the network and processes them through a named pipe system.

\sphinxAtStartPar
\sphinxstylestrong{The Main Dependecnes:}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxstylestrong{user:} processing
\item[] \sphinxhyphen{} \sphinxstylestrong{depends\sphinxhyphen{}on:}
\item[]
\begin{DUlineblock}{\DUlineblockindent}
\item[] \sphinxhyphen{} /data/config/config.json,
\item[] \sphinxhyphen{} storescpFIONA,
\item[] \sphinxhyphen{} receiveSingleFile.sh,
\item[] \sphinxhyphen{} processSingleFile.py
\end{DUlineblock}
\item[] \sphinxhyphen{} \sphinxstylestrong{log\sphinxhyphen{}file:}
\item[]
\begin{DUlineblock}{\DUlineblockindent}
\item[] \sphinxhyphen{} \$\{SERVERDIR\}/logs/storescpd\$\{projname\}.log,
\item[] \sphinxhyphen{} \$\{SERVERDIR\}/logs/storescpd\sphinxhyphen{}start.log
\end{DUlineblock}
\item[] \sphinxhyphen{} \sphinxstylestrong{pid\sphinxhyphen{}file:} \$\{SERVERDIR\}/.pids/storescpd\$\{projname\}.pid
\item[] \sphinxhyphen{} \sphinxstylestrong{start:} ./storectl.sh start {[}PROJECT\_NAME{]}
\item[] \sphinxhyphen{} \sphinxstylestrong{license:} TBE
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{Input/Output File Dependencies}

\sphinxincludegraphics{mermaid-aa473b54619391da30506c9d3fca2c7636ecd8db.pdf}

\sphinxAtStartPar
\sphinxstylestrong{File Descriptions:}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{config.json}} \sphinxhyphen{} Main configuration file containing DATADIR, DICOMPORT, and project settings
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{enabled}} \sphinxhyphen{} Control file to enable/disable the service (first character: 0=disabled, 1=enabled)
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{storectl.sh}} \sphinxhyphen{} Main control script for managing the DICOM storage daemon
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{storescpd.pid}} \sphinxhyphen{} Process ID file for tracking the running daemon
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{storescpd.log}} \sphinxhyphen{} Log file recording daemon activities and errors
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{processSingleFilePipe}} \sphinxhyphen{} Named pipe for communicating file reception events to processing system
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{Data Flow Dependencies}

\sphinxincludegraphics{mermaid-11e394135a2629a7c3c10f3946a24837dd34d222.pdf}

\sphinxAtStartPar
\sphinxstylestrong{File Descriptions}

\begin{DUlineblock}{0em}
\item[] 1. Input Files:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data/config/config.json}} \sphinxhyphen{} Main configuration file containing data directories and DICOM ports
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/data/enabled}} \sphinxhyphen{} Optional control file to disable the service (first character “0” disables)
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/usr/share/dcmtk/dicom.dic}} \sphinxhyphen{} DICOM dictionary file for parsing DICOM data structures
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] 2. Output Files:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{SERVERDIR\}/.pids/storescpd\$\{projname\}.pid}} \sphinxhyphen{} Process ID file for daemon management
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{SERVERDIR\}/logs/storescpd\$\{projname\}.log}} \sphinxhyphen{} Main service log file for daemon output
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{SERVERDIR\}/logs/storescpd\sphinxhyphen{}start.log}} \sphinxhyphen{} Startup log file for initialization messages
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{/tmp/.processSingleFilePipe\$\{projname\}}} \sphinxhyphen{} Named pipe for inter\sphinxhyphen{}process communication
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{Directories:}

\begin{DUlineblock}{0em}
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{DATADIR\}/site/archive}} \sphinxhyphen{} DICOM file storage location
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{DATADIR\}/site/.arrived}} \sphinxhyphen{} Temporary arrival directory
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{SERVERDIR\}/.pids/}} \sphinxhyphen{} PID file storage
\item[] \sphinxhyphen{} \sphinxcode{\sphinxupquote{\$\{SERVERDIR\}/logs/}} \sphinxhyphen{} Log file directory
\end{DUlineblock}


\subsubsection{storectl.sh}
\label{\detokenize{Architecture/scripts/storectl:id1}}
\sphinxAtStartPar
filename: storescpd

\sphinxAtStartPar
purpose: start storescp server for processing user at boot time to receive data
|         Move files to project specific file system

\sphinxAtStartPar
This system service will fail if a control file /data/enabled exists and  its first character is a “0”.

\sphinxAtStartPar
(Hauke Bartsch)

\sphinxstepscope


\subsection{whatIsInIDS7.py}
\label{\detokenize{Architecture/scripts/whatIsInIDS7:whatisinids7-py}}\label{\detokenize{Architecture/scripts/whatIsInIDS7::doc}}
\sphinxAtStartPar
TODO: check if the number of study related series is correct (looks too large in Export app)

\sphinxstepscope


\subsection{whatIsNotInIDS7.py}
\label{\detokenize{Architecture/scripts/whatIsNotInIDS7:whatisnotinids7-py}}\label{\detokenize{Architecture/scripts/whatIsNotInIDS7::doc}}
\sphinxAtStartPar
There is no docstring.


\chapter{Contact Information}
\label{\detokenize{index:contact-information}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Website: \sphinxurl{https://fiona.ihelse.net}

\item {} 
\sphinxAtStartPar
Location: Haukeland University Hospital, Bergen, Norway

\end{itemize}


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\DUrole{xref}{\DUrole{std}{\DUrole{std-ref}{genindex}}}

\item {} 
\sphinxAtStartPar
\DUrole{xref}{\DUrole{std}{\DUrole{std-ref}{modindex}}}

\item {} 
\sphinxAtStartPar
\DUrole{xref}{\DUrole{std}{\DUrole{std-ref}{search}}}

\end{itemize}



\renewcommand{\indexname}{Index}
\printindex
\end{document}