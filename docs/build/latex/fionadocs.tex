%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}
\setcounter{tocdepth}{0}



\title{FionaDocs}
\date{Aug 13, 2025}
\release{}
\author{Hauke Bartsch, Marek Kociński}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{Research Information System}
\label{\detokenize{index:research-information-system}}
\sphinxAtStartPar
The research information system (RIS) of the Western Norway Health Authorities (Helse\sphinxhyphen{}Vest) also called the “Steve Project” is a secure computer system that stores
research data for approved research projects at Haukeland University Hospital and connected hospitals of the Helse Vest region. The project is supported by the
radiology department of \sphinxhref{https://www.helse-bergen.no/en}{Mohn Medical Imaging and Visualization Centre} and the \sphinxhref{https:/mmiv.no}{Haukeland University Hospital} and approved for research project use by \sphinxhref{https://www.helse-vest-ikt.no}{Helse Vest IKT}. The physical location of the data is at the premises of IKT Helse Vest Norway. Dedicated storage area and research software (Sectra, IDS7) provides researchers with
appropriate permission access to their data. All data is stored in a de\sphinxhyphen{}identified format inside the RIS. Maintaining a coupling list is the responsibility of each project
and not part of the functionality of the RIS. Based on the REK/DIPA rules for each project a lifetime tracking of the research data
per project ensures that data can be anonymized based on data sharing requirements, and that data can be deleted at the end of the project phase \sphinxhyphen{} if
required. We suggest that research data is allowed to be fully anonymized at the end of the project and remain in RIS for general research access.
Key features of the RIS include:•
\begin{itemize}
\item {} 
\sphinxAtStartPar
Hosted side\sphinxhyphen{}by\sphinxhyphen{}side with the clinical PACS as an independent installation.

\item {} 
\sphinxAtStartPar
Accepts de\sphinxhyphen{}identified patient identifiers only.

\item {} 
\sphinxAtStartPar
All data is moved through a de\sphinxhyphen{}identification process upon import into RIS.

\item {} 
\sphinxAtStartPar
All data is assigned to one or more specific research projects and the visibility of data is restricted to individuals with project role access rights.

\item {} 
\sphinxAtStartPar
Projects require a valid REK approval, such documentation has to be provided at the start of a project by the project owner.

\item {} 
\sphinxAtStartPar
The project owner can identify additional user accounts that can access the data.

\item {} 
\sphinxAtStartPar
User access to the research PACS is controlled by IKT and requires a valid Haukeland University Hospital user account.

\end{itemize}

\sphinxstepscope


\section{END USER}
\label{\detokenize{EndUser/index:end-user}}\label{\detokenize{EndUser/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} Doctors, researchers, medical personnel


\subsection{Fiona system}
\label{\detokenize{EndUser/index:fiona-system}}
\sphinxAtStartPar
The Fiona system is a comprehensive solution for managing DICOM medical images in a research environment. The system enables automatic reception, processing, anonymization, and transfer of imaging data between Clinical and Research PACS (Picture Archiving and Communication System) systems.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{steve-project}.png}
\caption{Fiona front page.}\label{\detokenize{EndUser/index:id1}}\end{figure}


\subsection{New project: creation, setup and access}
\label{\detokenize{EndUser/index:new-project-creation-setup-and-access}}

\subsubsection{Apply for a new project}
\label{\detokenize{EndUser/index:apply-for-a-new-project}}
\sphinxAtStartPar
In order to apply for a new project on the research information system (research PACS)
please fill out the application form available under “\sphinxstylestrong{Apply for a new research project}”
here: \sphinxurl{https://fiona.local.server.no}.

\sphinxAtStartPar
Additional user access can be requested by the principal investigator of the project under
\sphinxhref{https://fiona.local.server.no/applications/Apply/}{Apply} (\sphinxurl{https://fiona.local.server.no/applications/Apply/}) “\sphinxstylestrong{Apply for access to an existing project}”.

\sphinxAtStartPar
If you encounter any problems with applying for access, contact \sphinxhref{mailto:admin@your-institution.com}{admin@your\sphinxhyphen{}institution.com}.


\subsubsection{Access to REDCap for structured data}
\label{\detokenize{EndUser/index:access-to-redcap-for-structured-data}}
\sphinxAtStartPar
Our project uses \sphinxhref{https://project-redcap.org}{REDCap} as an electronic data capture solution. Projects on the research information system can receive access to their RedCap project as well as access to the image data viewing (see next section).


\subsubsection{Access to the “Sectra DMA Forskning” research PACS viewer}
\label{\detokenize{EndUser/index:access-to-the-sectra-dma-forskning-research-pacs-viewer}}
\sphinxAtStartPar
Access to the image data is provided by your \sphinxhref{https://it.department.you.institution.no}{IT Department}. Such access may require a valid local hospital user account and a laptop or PACS workstation that is under control of IT Department. If you contact IT Departmetn ask for the start menu item “\sphinxstylestrong{Sectra DMA Forskning}”. With the program and your hospital username and password you will gain access to the research picture archive and communication system (PACS).

\sphinxAtStartPar
Without access to a specific research project you will not see any data in the research PACS. Each research projects requires specific permissions to become accessible for a user.

\sphinxAtStartPar
The research PACS viewer is using a separate clinical PACS software installation (Sectra IDS7). In order to prevent possible interactions between the clinical and the research PACS only one of the application can run at a given time. You will be logged out of the clinical PACS if you start the research PACS viewer.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.75]{{sectra-2}.png}
\caption{Forskning PACS log\sphinxhyphen{}inn window to view image data by project.}\label{\detokenize{EndUser/index:id2}}\end{figure}


\subsection{Submit data to the Research Information System}
\label{\detokenize{EndUser/index:submit-data-to-the-research-information-system}}
\sphinxAtStartPar
\sphinxstylestrong{The Research Information System} (RIS) contains two components. First, image data is stored in the Sectra DMA Forskning \sphinxhyphen{} an image viewer with a vendor neutral archive (VNA). Second, all meta\sphinxhyphen{}data is stored in table format in an electronic data capture system REDCap, that is Fiona server on port 4444, (\sphinxurl{https://fiona.local.server.no:4444}). Sending image data will create the appropriate entries in \sphinxhref{https://fiona.local.server.no:4444}{RedCap (Fiona, port 4444)}. Additional data collection instruments can be set up there and used to capture assessments, consent/assent and results from automated image processing. All image data is assigned to a project to allow for project specific data views for each research information user.

\sphinxAtStartPar
The basic steps to submit data are:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Send DICOM studies to “HBE Fiona” or “Fiona” (modality station)

\item {} 
\sphinxAtStartPar
\sphinxhref{https://fiona.local.server.no/applications/Assign/}{Assign} to project on \sphinxurl{https://fiona.local.server.no/applications/Assign/}.

\end{enumerate}

\sphinxAtStartPar
In step 1 data arrives in a \sphinxstylestrong{quarantine} location. In step 2 each DICOM study needs to be \sphinxstylestrong{assigned to project}, pseudonymized participant identifier and event name before it will be forwarded to the research PACS and becomes visible to the project users.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{fiona-assign-view}.png}
\end{figure}



\sphinxAtStartPar
\sphinxstylestrong{Setup of a new project}

\sphinxAtStartPar
The project needs to exist on the research information system before participant data is collected. After a successful setup your project and event names should appear in the Assign application.


\subsubsection{\sphinxstylestrong{How to add image data}}
\label{\detokenize{EndUser/index:how-to-add-image-data}}
\sphinxAtStartPar
The end\sphinxhyphen{}point for images is \sphinxhref{https://fiona.local.server.no}{Fiona} (\sphinxurl{https://fiona.local.server.no}):
\begin{itemize}
\item {} 
\sphinxAtStartPar
AETitle: \sphinxhref{AETtitle}{Application Entity Title}

\item {} 
\sphinxAtStartPar
\sphinxhref{fiona:local.ip}{IP: xxx.xxx.xxx.xxx}

\item {} 
\sphinxAtStartPar
Port: 11112

\end{itemize}

\sphinxAtStartPar
Images that arrive at this endpoint are added to a quarantine system (FIONA, \sphinxurl{https://fiona.local.server.no:4444}) running the REDCap software. Automatic routing rules (stored in REDCap) are used to anonymize and forward the data to the image storage. If such routing has not been set up, the “Assign” application (see below) needs to be used to forward individual studies based on pre\sphinxhyphen{}existing patient ID lists.

\sphinxAtStartPar
From Sectra Production you can send image data to the endpoint “HBE Fiona”. Modality stations might also have the “FIONA” endpoint setup. If the data is already anonymized and has a de\sphinxhyphen{}identified PatientName/PatientID entry that indicates the project the FIONA system will attempt to de\sphinxhyphen{}identify (pseudonymization) further DICOM tags and forward the images to IDS7 (may take minutes). No further action is needed. If you suspect this did not work, see the corresponding section about the representation of transfers in REDCap.

\sphinxAtStartPar
Image data that contains patient information cannot be automatically assigned to the appropriate project as there is only a single endpoint for FIONA shared by all projects. To assign participants correctly to projects and de\sphinxhyphen{}identified participant identifiers a user can perform the assignment to project, participant ID and event name in the “Assign” web application.

\sphinxAtStartPar
If the participant identifiers do not exist yet user may add new project specific identifiers in “Assign”. Such identifiers need to follow the naming rules for a project and are verified using regular expression pattern specific for each project.

\sphinxAtStartPar
The web application for the assignment of scans forwarded to HBE Fiona is available at: \sphinxurl{https://fiona.local.server.no/applications/Assign/}.

\sphinxAtStartPar
On the Assign website look for your forwarded study. It should appear in about 15 min.
Identify the correct scan using the Accession Number (Undersøkelse\sphinxhyphen{}ID) or the date and time
of the scan. Select your project from the drop\sphinxhyphen{}down. This will fill in the list of patient names
and event names. Select the correct patient name and the event this study belongs to. After
a couple of seconds a new button appears below the study entry. Use it to select and
confirm the assignment. This will forward a de\sphinxhyphen{}identified version of the study data to “Sectra
Forskning”. If you do not assign your data on Assign they will not be forwarded. After a
couple of days (7 days) such data will disappear from the list. Send an email to \sphinxhref{mailto:admin@your-institution.com}{Local Fiona Admin} to request a resend.

\sphinxAtStartPar
\sphinxstylestrong{Verification steps}

\sphinxAtStartPar
After data arrived at the research PACS a verification step should ensure that all images have been received at the quarantine on FIONA and have been forwarded to research PACS. This can be done by comparing the number of images on the sending station with the number of images in IDS7.

\sphinxAtStartPar
Furthermore the import step will also attempt to de\sphinxhyphen{}identify secondary capture images with burned in image information. This process is fully automated and can result in false positive and occasionally false negative results. After a review of the data in IDS7 the user may decide which secondary image series are “safe” to exclude from the pixel rewriting on import. For example a secondary capture series from DTI may not contain any burned in names or identifying numbers or dates. Such image series can be removed in REDCap from further pixel anonymization.

\sphinxAtStartPar
If the number of images on FIONA does not correspond to the number of images available cache previous assignments and automatically forward such images to the research PACS using the previously defined project, patient identifier and event name.

\sphinxAtStartPar
\sphinxstylestrong{Features for data migration}

\sphinxAtStartPar
The \sphinxhref{https://fiona.local.server.no/applications/Assign/}{Assign} web\sphinxhyphen{}application allows users to upload a coupling list that maps the accession
number (Undersøkelse\sphinxhyphen{}ID) of the study to the pseudonymized participant identifier. Such
mappings must be uploaded before the first image study of the project has been forwarded
to FIONA. Incoming DICOM studies in FIONA that match entries in the coupling list will
automatically be assigned to the project.

\sphinxAtStartPar
\sphinxstylestrong{How to handle errors?}

\sphinxAtStartPar
Correcting errors during data import are not difficult to fix. Try to follow up on such errors
on an ongoing basis. The quarantine FIONA station may have still have a copy of the data in
its cache which simplifies the process. Contact \sphinxhref{mailto:admin@your-institution.com}{Local Fiona Admin} in such cases and ask for help. This will allow you to fix issues such as:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Wrong assignment of participant identifiers to DICOM studies

\item {} 
\sphinxAtStartPar
Wrong assignment of event names to DICOM studies

\item {} 
\sphinxAtStartPar
Missing images or image series for existing DICOM studies

\item {} 
\sphinxAtStartPar
Missing entries for DICOM studies on “Assign”.

\end{itemize}


\subsection{Export image data from research PACS}
\label{\detokenize{EndUser/index:export-image-data-from-research-pacs}}
\sphinxAtStartPar
Data in the research PACS is secured by generic procedures during data import that delete or rewrite some DICOM tags, changes dates and replaces unique identifiers. A documentation of this process is available on the GitHub repository of the projects for removal of DICOM meta\sphinxhyphen{}tags: \sphinxhref{https://github.com/mmiv-center/DICOMAnonymizer}{DICOMAnonymizer}, and for the removal of burned in image information: \sphinxhref{https://github.com/mmiv-center/RewritePixel}{RewritePixel}.

\sphinxAtStartPar
Data stored in the research PACS is therefore in general suited for data sharing IF pseudonymized data is allowed. In order to support users with the task of data pseudonymization the research information system provides the “Review” web application that lists all existing DICOM tags in a research project (\sphinxurl{https://fiona.local.server.no}).

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Pseudonymized data is defined here as data for which a coupling list exists somewhere in the universe. This is in contrast to anonymized data where such a list does not exist and can also not be created.
\end{sphinxadmonition}

\sphinxAtStartPar
Further de\sphinxhyphen{}identification procedures might require changes to image data such as face stripping, removal of outer ear tissue, cortical folding pattern, etc.. Such potential sources of information for re\sphinxhyphen{}identification have been proposed in the literature but actual attacks based on them have not recently been documented. Better documented and perhaps more relevant are re\sphinxhyphen{}identification using spreadsheet data where external sources are linked to the projects data to discover the supposedly hidden identity of the research participants. For example it might be possible to link Gender, day of birth and the hospital name to a real participant name using a birth or voting registry.

\sphinxAtStartPar
\sphinxstylestrong{Export using IDS7}

\sphinxAtStartPar
The image data from a study can be exported from the research PACS using a right\sphinxhyphen{}click menu entry available in the Informasjonsvindu “Exporter til medium”. Such exports will generate either a derived patient ID \textendash{} if an Anonymization Profile is selected or a faithful copy of the data with all pseudonymized DICOM tags intact.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
This export does not prevent re\sphinxhyphen{}identification. Specifically the PatientID field is created from the pseudonymized ID used in the research PACS and therefore not random.
\end{sphinxadmonition}

\sphinxAtStartPar
The export is also case\sphinxhyphen{}by\sphinxhyphen{}case, which is tedious if many data need to be exported. The export will also result in directory names that do not reflect the research project structure as participant identifier \textendash{} event name \textendash{} modality \textendash{} image series. It may be advantageous to export from IDS7 if a single image study needs to be shared without special requirements. Such export folders will also contain an image viewer.

\sphinxAtStartPar
\sphinxstylestrong{Export to project specific formats, NIfTI and zip\sphinxhyphen{}files}

\sphinxAtStartPar
The research information system supports a separate export facility that is more suited to implement project specific de\sphinxhyphen{}identification. Such export requirements include specific DICOM value changes (replacing underscores with dashes), adding birth date information back, formatting and cleaning of series descriptions, zip\sphinxhyphen{}file exports with specific folder structures etc.. This export is appropriate if the receiving institution has specific requirements on how data should be shared.

\sphinxAtStartPar
Request access to the specialized data exports for your project from \sphinxhref{mailto:admin@your-institution.com}{Local Fiona Admin}. Provide your export specification and we will implement your anonymization scheme and make it available to you and other researchers. As an example the “Export” application currently supports the export in NIfTI formats (using dcm2niix) and the export in several zip\sphinxhyphen{}file formats.


\subsection{End\sphinxhyphen{}user contract}
\label{\detokenize{EndUser/index:end-user-contract}}
\begin{sphinxadmonition}{attention}{Attention:}
\sphinxAtStartPar
The following text is from the Apply website for the Steve system. Please check this page for updates to the wording.
\end{sphinxadmonition}

\sphinxAtStartPar
By creating a project on the research information system you agree to the following:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
All data stored in the RIS belongs to the research project owner represented by the PI of the project. Adding and verifying added data to the RIS is the responsibility of the project owner. The RIS team will help research projects to automate this process.

\item {} 
\sphinxAtStartPar
Sensitive participant information needs to be stored under a separate account and needs to be accessible to authorized (data\sphinxhyphen{}manager and above) user accounts only. All other research data is stored as de\sphinxhyphen{}identified data (pseudonymized, with external coupling list) or in an anonymized format. This restriction includes sensitive information such as Norwegian identification numbers, real names or parts of real names, other birth certificate information and initials. It is the responsibility of the project to review the result of the de\sphinxhyphen{}identification procedures implemented by the RIS team on image meta\sphinxhyphen{}data using \sphinxurl{https://fiona.local.server.no/applications/ReviewDICOMTags/} and the result of the detection and removal of burned in image data (IDS7). The project will inform the RIS team in a timely manner if the pseudonymization procedure of the RIS team needs to be updated. This restriction is in place to allow for the largest possible user base for the RIS including PhD students and external collaborators.

\item {} 
\sphinxAtStartPar
All research data is stored as part of RIS projects identified by a project name  of 5\sphinxhyphen{}20 characters. Users can gain access to the data upon request from the project PI or an appointed representative of the PI.

\item {} 
\sphinxAtStartPar
Projects are expected to utilize best\sphinxhyphen{}practises for data handling such as  accounts based on roles like data\sphinxhyphen{}entry (add data only) and data\sphinxhyphen{}manager (change data, export data). Personally identifying fields have to be marked as such (Identifier? field of the instrument designer) and data access groups shall be used for multi\sphinxhyphen{}site project setups.

\end{enumerate}

\sphinxAtStartPar
5. Projects will undergo a short review from the RIS team before they are moved by the RIS team from development mode into production mode for data capture. This review may generate suggestions for the project on how to implement best practices for longitudinal data captures, missing validation and the use of additional software features. All research data is collected and stored with a valid REK approval for the time period specified in the REK approval. The REK approval is required at the time that the RIS project is created. Any change of the REK approval start and end dates need to be
reported to the RIS team. At the end of the project period data can be either a) deleted or b) fully anonymized (suggested choice). It is up to the project to inform the RIS team about the correct way of handling the data at the end of the project. By default we will assume that data needs to be deleted. Based on the project end date (REK) the RIS team will inform the PI of the project of a pending change of the project status to the archive state. An archive state project will not allow for further data entry, or changes to captured data. After a period of about 1 year the project data will be exported and provided to the project PI for download. An archived project can be deleted by the RIS team after an unspecified time period. If the project data can be fully anonymized, the RIS team may create a copy of the data with new participant identifiers (without a coupling list). After a re\sphinxhyphen{}import a fully anonymized version of the project data can become accessible to other RIS users. The original project
data will change to archive state, a copy is provided to the projects PI and the data can be deleted by the RIS team after about 1 year.


\subsection{Sensitive Data Projects}
\label{\detokenize{EndUser/index:sensitive-data-projects}}

\subsubsection{Separation of Sensitive Information and Data}
\label{\detokenize{EndUser/index:separation-of-sensitive-information-and-data}}
\sphinxAtStartPar
A sensitive data project is one that is used to capture human subject data and in general will require  REK (regional ethics board approval). In order to setup such a project in REDCap we suggest the follow structure and features of REDCap to be used. These recommendations have been generated based
on discussions in relevant risk assessments.

\sphinxAtStartPar
All sensitive data should be stored in a separate REDCap “ID” project including Norwegian Identification Numbers, names or parts of names, addresses and full birth dates (see Figure 1). This project should have its own roles of “Data Manager”, “Data Entry”, and “Controller”. People with permission to access and/or edit this information can use this database to keep contact information up\sphinxhyphen{}to\sphinxhyphen{}date and to enroll new participants into the study. Each participant should be assigned a pseudonymized ID in the sensitive data project that links the entry to the corresponding participant in the data project. Examples for this ID are:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\textless{}project name\textgreater{}\sphinxhyphen{}\textless{}site number\textgreater{}\sphinxhyphen{}0001,

\item {} 
\sphinxAtStartPar
\textless{}project name\textgreater{}\sphinxhyphen{}\textless{}site number\textgreater{}\sphinxhyphen{}0002,

\item {} 
\sphinxAtStartPar
etc..

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{redcap-sensitive-data}.png}
\caption{Sensitive data projects should be split into a REDCap project for data (using pseudonymized ids) and a REDCap project for sensitive data including the coupling list.}\label{\detokenize{EndUser/index:id3}}\end{figure}

\sphinxAtStartPar
All other data should be stored in a separate REDCap “Data” project using the pseudonymized articipant ID as a “record\_id” (first field in the study).

\sphinxAtStartPar
\sphinxstylestrong{User rights management}

\sphinxAtStartPar
When a project leader / principal investigator (PI) is given a REDCap account and project, they are given “project owner” roles. The project owner can then provide access to project members in “roles”. A role defines a given set of custom permissions which defines the user’s access to data, export permissions and ability to make changes to data.

\sphinxAtStartPar
Each project can have predefined roles. We recommend the predefined roles:
\begin{itemize}
\item {} 
\sphinxAtStartPar
“Data Manager” (ability to change study design, export),

\item {} 
\sphinxAtStartPar
“Data Entry” (add, change, or delete data),

\item {} 
\sphinxAtStartPar
“Controller” to define roles for data viewing, editing, and deleting records.

\end{itemize}

\sphinxAtStartPar
In more complex cases, different access settings can be given on different forms in the study (see also API access with REDCap). Individual users are assigned to project roles as part of gaining access to one project.

\sphinxAtStartPar
The user rights management is the responsibility of the project owner and/or the users they add to the project with User Rights access. User roles should be set at the lowest access level that is necessary (e.g., export rights only for users who need this permission). Access to the project should be reviewed regularly and personnel who no longer require access need to be removed from the project.

\sphinxAtStartPar
\sphinxstylestrong{User rights \textendash{} multi\sphinxhyphen{}center projects}

\sphinxAtStartPar
In a project where several institutions participate with their own project participants (several hospitals etc.) each group of participants should be assigned to a separate “data access group”. This functionality allows records in a study to be part of the user rights management. A user with access to a single data access group can only see participants that belong to this group. If this user creates a new participant, they will be automatically assigned to the group.

\sphinxAtStartPar
\sphinxstylestrong{How to handle Email Addresses in Data Projects}

\sphinxAtStartPar
Email addresses are special identifying fields that can be stored in data projects for the purpose of creating automated invites for participants to fill out forms from home. In projects that use this feature email fields need to be present in the data project in order to allow for email distribution to participants.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Add such email fields to a separate instrument of the REDCap data project and mark the instrument as viewable by specific roles only (like Data Managers).

\item {} 
\sphinxAtStartPar
Mark the email field as an “Identifier” field to prevent export of the field’s data by user  of roles that cannot view sensitive fields.

\item {} 
\sphinxAtStartPar
Add the Action Tag “@PASSWORDMASK” to the field to prevent accidental viewing of the fields values if the instrument is displayed on screen.

\item {} 
\sphinxAtStartPar
Add a field validation as “Email” to prevent some miss\sphinxhyphen{}typing of emails.

\end{enumerate}


\subsubsection{Randomization}
\label{\detokenize{EndUser/index:randomization}}
\sphinxAtStartPar
Randomized studies have can remove biases caused by selection of participants for specific arms in a study. Such biases can prevent a fair assessment of a treatment option. The randomization feature of REDCap allows users to upload a randomization table that has been externally created before the start of the study \textendash{} usually by the statistician of the project. After participants are enrolled into the study the randomization entries for that person are “opened” and the choice of the randomization is stored in the project.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{sensitive-data-randomization}.png}
\caption{Basics of the randomization workflow in REDCap.}\label{\detokenize{EndUser/index:id4}}\end{figure}


\subsubsection{e\sphinxhyphen{}Consent}
\label{\detokenize{EndUser/index:e-consent}}
\sphinxAtStartPar
In an e\sphinxhyphen{}Consent workflow the basics of the paper informed consent are maintained. An electronic consent document is created based on the approved language and design of the paper consent using HTML features in REDCap. The solution supports signature fields (stored as images) and creates resulting PDF (paper) versions of the consent as well as electronic versions of the consent. The following figures show some of the setup and resulting documentation that is created in the solution.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{sensitive-data-e-consent}.png}
\caption{Setup of e\sphinxhyphen{}Consent in REDCap with identification of typed information for participant name and signature fields.}\label{\detokenize{EndUser/index:id5}}\end{figure}

\sphinxAtStartPar
We suggest exporting e\sphinxhyphen{}Consent documents and to store them centrally by the project administration outside of REDCap.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{sensitive-data-e-consent-user-view}.png}
\caption{Example e\sphinxhyphen{}Consent document structure (left) with (right) visual representation and signature (middle, bottom).}\label{\detokenize{EndUser/index:id6}}\end{figure}

\sphinxAtStartPar
As informed consent document contain the name of the signatory and the one countersigning the informed consent process the e\sphinxhyphen{}Consent workflow should be implemented in the sensitive data (ID) REDCap project.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{sensitive-data-e-consent-in-person}.png}
\caption{Internal documentation of e\sphinxhyphen{}Consent in REDCap. Signatures have been captured and tracked. A paper version for export is available.}\label{\detokenize{EndUser/index:id7}}\end{figure}


\subsubsection{Automatic data exports from REDCap}
\label{\detokenize{EndUser/index:automatic-data-exports-from-redcap}}
\sphinxAtStartPar
Data may be exported from REDCap using the REDCap API, a technical interface to automate the export of project and participant information using scripting. To provide such access a dedicated user\sphinxhyphen{}account “api\_\textless{}real username\textgreater{}” should be created which is specific for a single project. Configure the account with a limited set of read permissions to specific fields or instruments using a new API role. The REDCap API will borrow these restrictive permissions for controlled access.

\sphinxAtStartPar
Setup: An administrator can generate an API “token” for this account and share the token and examples of accessing the resource (curl\sphinxhyphen{}based access) with the user.

\sphinxAtStartPar
Any change in the role of the \textless{}real username\textgreater{} should also apply to the connected API account. Specifically loosing access to the project should be implemented for both \textless{}real username\textgreater{} and api\_\textless{}real username\textgreater{}.


\subsubsection{Steps at the end of a REDCap project}
\label{\detokenize{EndUser/index:steps-at-the-end-of-a-redcap-project}}
\sphinxAtStartPar
REDCap is a tool for data collection. At the end of data capture projects using REDCap receive a notification of study end. At this point projects may provide updated REK information (extension of data capture notice). If no such notice is received REDCap projects will:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Lock all data participants (no further update/add).

\item {} 
\sphinxAtStartPar
Provide a copy of the REDCap project (CDISC format) to the project’s principal investigator or delegate.

\item {} 
\sphinxAtStartPar
Provide a copy of the project data (CSV) and data dictionary (PDF) to the principal investigator or delegate.

\item {} 
\sphinxAtStartPar
Request a confirmation that project data (CDISC and CSV) have been received by the project.

\item {} 
\sphinxAtStartPar
Permanently delete all project data.

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{redcap-end-of-project}.png}
\caption{End\sphinxhyphen{}of\sphinxhyphen{}project tracking for REDCap projects}\label{\detokenize{EndUser/index:id8}}\end{figure}

\sphinxAtStartPar
This process will be documented in the REDCap project tracking project “DataTransferProjects”, the project management tool with information on identity of the person requesting project removal and confirmations for all steps of the project removal process.


\subsection{External resources}
\label{\detokenize{EndUser/index:external-resources}}

\subsubsection{Git\sphinxhyphen{}Hub Repositories}
\label{\detokenize{EndUser/index:git-hub-repositories}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxhref{https://github.com/mmiv-center/FionaDocs}{Fiona Documentation Repository} \sphinxhyphen{} \sphinxurl{https://github.com/mmiv-center/FionaDocs}

\item {} 
\sphinxAtStartPar
\sphinxhref{https://github.com/mmiv-center/DICOMAnonymizer}{DICOMAnonymizer} \sphinxhyphen{} \sphinxurl{https://github.com/mmiv-center/DICOMAnonymizer}

\item {} 
\sphinxAtStartPar
\sphinxhref{https://github.com/mmiv-center/RewritePixel}{RewritePixel} \sphinxhyphen{} \sphinxurl{https://github.com/mmiv-center/RewritePixel}

\end{enumerate}


\subsubsection{REDCap}
\label{\detokenize{EndUser/index:redcap}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxhref{https://project-redcap.org}{REDCap} \sphinxhyphen{} \sphinxurl{https://project-redcap.org}

\end{enumerate}

\sphinxstepscope


\section{ADMINISTRATION}
\label{\detokenize{ServerAdmin/index:administration}}\label{\detokenize{ServerAdmin/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} IT administrators, DevOps

\sphinxstepscope


\section{ARCHITECTURE}
\label{\detokenize{Architecture/index:architecture}}\label{\detokenize{Architecture/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} Developers, system architects


\subsection{Folder and File structure}
\label{\detokenize{Architecture/index:folder-and-file-structure}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/home/processing/
|          └── bin/
│               ├── anonymizeAndSend.py
│               ├── clearExports.sh
│               ├── clearOldFiles.sh
│               ├── clearStaleLinks.sh
│               ├── createTransferRequestsForProcessed.py
│               ├── createTransferRequests.py
│               ├── populateAutoID.py
│               ├── populateIncoming.py
│               ├── populateProjects.py
│               └── utils/
│                      ├── getAllPatients2.sh
│                      ├── parseAllPatients.sh
│                      ├── resendProject.py
│                      ├── whatIsInIDS7.py
│                      └── whatIsNotInIDS7.py
│
/var/
  └── www/
       └── html/
             ├── applications/
             │          ├── Assign/
             │          │     └── php
             |          |          └── removeOldEntries.sh
             │          ├── Attach/
             │          │     └── process\PYGZus{}tiff.sh
             │          ├── Exports/
             │          │     └── php
             |          |          └── createZipFileCmd.php
             │          ├── User/
             │          │     └── asttt/
             │          │            └── code/
             │          │                  └── cron.sh
             │          └── Workflows/
             │                 └──php
             |                    └── runOneJob.sh
             │
             └── server/
                    ├── bin/
                    |    ├── heartbeat.sh
                    |    ├── processSingleFile3.py
                    |    ├── sendFiles.sh
                    |    └── storectl.sh
                    |
                    └── utils/
                          └── s2m.sh
\end{sphinxVerbatim}


\subsection{Components}
\label{\detokenize{Architecture/index:components}}
\sphinxstepscope


\subsubsection{anonymizeAndSend.py}
\label{\detokenize{Architecture/scripts/anonymizeAndSend:anonymizeandsend-py}}\label{\detokenize{Architecture/scripts/anonymizeAndSend::doc}}
\sphinxAtStartPar
For each transfer request created by createTransferRequests.py this script will anonymized all DICOM files before forwarding them to research PACS storage. Successful storage is marked in REDCap’s TransferRequest table (project Incoming). If errors are found during anonymization or during sending to research PACS errors are added to the TransferRequest REDCap table. Such errors are indicated by Assign as orange highlights.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\begin{itemize}
\item {} 
\sphinxAtStartPar
createTransferRequests.py (/home/processing/transfer\_requests)

\item {} 
\sphinxAtStartPar
REDCap \sphinxurl{https://localhost:4444/} (project Incoming, table TransferRequests)

\item {} 
\sphinxAtStartPar
Series level JSON files in: /data/site/raw/\sphinxstyleemphasis{/}/{\color{red}\bfseries{}*}.json

\end{itemize}

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/anonymizeAndSend.log,

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/anonymizeAndSend.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/1 * * * *  /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/anonymizeAndSend.pid /home/processing/bin/anonymizeAndSend.py \textgreater{}\textgreater{} /home/processing/logs/anonymizeAndSend.log 2\textgreater{}\&1

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/anonymizeAndSend:notes}}
\sphinxAtStartPar
During anonymization every study is marked with a StudyInstanceUID that identifies them as already anonymized. Currently the check performed will look for a specific root UID (“1.3.6.1.4.1.45037”) followed by a dot and a numeric sequence (without further dots).

\sphinxstepscope


\subsubsection{clearExports.sh}
\label{\detokenize{Architecture/scripts/clearExports:clearexports-sh}}\label{\detokenize{Architecture/scripts/clearExports::doc}}
\sphinxAtStartPar
Delete old entries in the /export2/Export/ folder (temporary folders older than 1000 minutes, requires permissions for processing user) and the oldest created zip files in /export2/Export/files/ until at least 90\% of space is available on this partition.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /export2/Export/files/
\sphinxhyphen{} /export2/Export/tmp\_*

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/clearExports.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/clearExports.pid

\item {} 
\sphinxAtStartPar
start:
0 23 * * 3,6 /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/clearExports.pid /home/processing/bin/clearExports.sh \textgreater{}\textgreater{} /home/processing/logs/clearExports.log 2\textgreater{}\&1

\end{itemize}

\sphinxstepscope


\subsubsection{clearOldFiles.sh}
\label{\detokenize{Architecture/scripts/clearOldFiles:clearoldfiles-sh}}\label{\detokenize{Architecture/scripts/clearOldFiles::doc}}
\sphinxAtStartPar
Delete the oldest files until we have at least 20\% free space on the data partition. This ensures that we can always receive new data on FIONA. Existing data that is not assigned (Assign) to a research project will be deleted.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /data/site/archive

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/clearOldFiles.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/clearOldFiles.pid

\item {} 
\sphinxAtStartPar
start:
30 * * * * /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/clearOldFiles.pid /home/processing/bin/clearOldFiles.sh \textgreater{}\textgreater{} /home/processing/logs/clearOldFiles.log 2\textgreater{}\&1

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/clearOldFiles:notes}}
\sphinxAtStartPar
TODO: delete links in /data/site/participants/
TODO: delete links in /data/site/srs/

\sphinxstepscope


\subsubsection{clearStaleLinks.sh}
\label{\detokenize{Architecture/scripts/clearStaleLinks:clearstalelinks-sh}}\label{\detokenize{Architecture/scripts/clearStaleLinks::doc}}
\sphinxAtStartPar
Delete links that do not point to real images in archive.

\sphinxAtStartPar
Just to be sure we have a clear /data/site/raw folder we remove broken symbolic link and empty folders.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /data/site/raw

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/clearStaleLinks.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/clearStaleLinks.pid

\item {} 
\sphinxAtStartPar
start:
2 3 * * * /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/clearStaleLinks.pid /home/processing/bin/clearStaleLinks.sh \textgreater{}\textgreater{} /home/processing/logs/clearStaleLinks.log 2\textgreater{}\&1

\end{itemize}

\sphinxstepscope


\subsubsection{createTransferRequests.py}
\label{\detokenize{Architecture/scripts/createTransferRequests:createtransferrequests-py}}\label{\detokenize{Architecture/scripts/createTransferRequests::doc}}
\sphinxAtStartPar
Create a transfer request json in /home/processing/transfer\_requests based on all existing records in REDCap’s Incoming project. If there is no transfer date yet for an Incoming study or, if the transfer date is before the newest series date (JSON modification date in /data/site/raw) a new transfer request is created for anonymizeAndSend.py.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} anonymizeAndSend.py (processes files created in /home/processing/transfer\_requests)
\sphinxhyphen{} REDCap \sphinxurl{https://localhost:4444/} (project Incoming, table TransferRequests)
\sphinxhyphen{} Series level JSON files in: /data/site/raw/\sphinxstyleemphasis{/}/{\color{red}\bfseries{}*}.json

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/createTransferRequests.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/createTransferRequests.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/1 * * * *  /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/createTransferRequests.pid /home/processing/bin/createTransferRequests.py \textgreater{}\textgreater{} /home/processing/logs/createTransferRequests.log 2\textgreater{}\&1

\end{itemize}

\sphinxstepscope


\subsubsection{createTransferRequestsForProcessed.py}
\label{\detokenize{Architecture/scripts/createTransferRequestsForProcessed:createtransferrequestsforprocessed-py}}\label{\detokenize{Architecture/scripts/createTransferRequestsForProcessed::doc}}
\sphinxAtStartPar
Detect if we have image series forwarded to FIONA
that belong to a study that already exists on the research PACS.
This happens if data is forwarded from the research PACS to a
workstation. The workstation procudes new image series and forwards
those to FIONA. There is no transfer request for them so they are not
automatically forwarded and Assign is not displaying them because
they have a study instance uid without a dot.

\sphinxAtStartPar
We want to forward them by first finding them (no dot in raw and dot
in series). Change their StudyInstanceUID to the incoming
one that has a transfer request. Send them to fiona so they will
show up in the correct folder, be detected as new incoming series for
existing study and auto forward using createTransferRequests.py.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} REDCap Incoming project

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/createTransferRequestsForProcessed.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/createTransferRequestsForProcessed.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/30 * * * * /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/createTransferRequestsForProcessed.pid /home/processing/bin/createTransferRequestsForProcessed.py \textgreater{}\textgreater{} /home/processing/logs/createTransferRequestsForProcessed.log 2\textgreater{}\&1

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/createTransferRequestsForProcessed:notes}}
\sphinxAtStartPar
This script will create a SeriesInstanceUID compatible with FIONA’s anonymizer and use it to mark the new image series. If this identifier is changed the script needs to be updated.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{:}\PYG{n}{lineos}\PYG{p}{:}

\PYG{k}{def}\PYG{+w}{ }\PYG{n+nf}{hashID}\PYG{p}{(} \PYG{n}{SeriesInstanceUID} \PYG{p}{)}\PYG{p}{:}
    \PYG{c+c1}{\PYGZsh{} do the same operation that would be done by the anonymizer}
    \PYG{c+c1}{\PYGZsh{} get a safe string}
    \PYG{n}{s} \PYG{o}{=} \PYG{n}{SeriesInstanceUID}\PYG{o}{.}\PYG{n}{encode}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{utf\PYGZhy{}8}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{org\PYGZus{}root} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{1.3.6.1.4.1.45037}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{n}{h} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZpc{}s}\PYG{l+s+s2}{.}\PYG{l+s+si}{\PYGZpc{}s}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{\PYGZpc{}} \PYG{p}{(}\PYG{n}{org\PYGZus{}root}\PYG{p}{,} \PYG{n}{hashlib}\PYG{o}{.}\PYG{n}{sha256}\PYG{p}{(}\PYG{n}{s}\PYG{p}{)}\PYG{o}{.}\PYG{n}{hexdigest}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
    \PYG{k}{return} \PYG{n}{h}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{:}\PYG{l+m+mi}{63}\PYG{p}{]}
\end{sphinxVerbatim}

\sphinxstepscope


\subsubsection{createZipFileCmd.php}
\label{\detokenize{Architecture/scripts/createZipFileCmd:createzipfilecmd-php}}\label{\detokenize{Architecture/scripts/createZipFileCmd::doc}}
\sphinxAtStartPar
System service used by the Export application to create zip\sphinxhyphen{}compressed files.

\sphinxAtStartPar
The command is called by cron approximately every 3 minutes. Data for export is requested from research PACS and
stored inside a zip file in a export\sphinxhyphen{}type specific format. Exports in ‘PURE’ format for example are sorted into
series directories.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /export2/Export/files/
\sphinxhyphen{} /var/www/html/applications/Exports/php/execMeasurements.json (adds processing times by project)

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/Exports\_PrepareDownload.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/Exports\_PrepareDownload.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/3 * * * * /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/Exports\_PrepareDownload.pid /usr/bin/php /var/www/html/applications/Exports/php/createZipFileCmd.php \textgreater{}\textgreater{} /home/processing/logs/Exports\_PrepareDownload.log 2\textgreater{}\&1

\end{itemize}

\sphinxstepscope


\subsubsection{cron.sh}
\label{\detokenize{Architecture/scripts/cron:cron-sh}}\label{\detokenize{Architecture/scripts/cron::doc}}
\sphinxAtStartPar
System service for the ASTTT service of the profile page on FIONA. Sends out emails if data arrives for projects the user is a member off.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /var/www/html/applications/User/asttt/

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/User\_asttt.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/User\_asttt.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/30 * * * * /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/User\_asttt.pid /var/www/html/applications/User/asttt/code/cron.sh \textgreater{}\textgreater{} /home/processing/logs/User\_asttt.log 2\textgreater{}\&1

\end{itemize}

\sphinxstepscope


\subsubsection{getAllPatients2.sh}
\label{\detokenize{Architecture/scripts/getAllPatients2:getallpatients2-sh}}\label{\detokenize{Architecture/scripts/getAllPatients2::doc}}
\sphinxAtStartPar
Populate the WhatIsInIDS7 table in REDCap for a specific project using findscu. This script is part of a sequence of scripts: getAllPatients2.sh \sphinxhyphen{} parseAllPatients.sh \sphinxhyphen{} whatIsInIDS7.py.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /tmp/parseAllPatients\{projname\}/
\sphinxhyphen{} /tmp/pullStudies\{projname\}/

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/whatIsInIDS7\{projname\}.log,

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/whatIsInIDS7\{projname\}.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/48 * * * * /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/getAllPatients2\{projname\}.pid /bin/bash \sphinxhyphen{}c “/home/processing/bin/utils/getAllPatients2.sh 10000 “\{proejct\}” \textgreater{}\textgreater{} /home/processing/logs/whatIsInIDS7/whatIsInIDS7\{projname\}.log 2\textgreater{}\&1 \&\& /home/processing/bin/utils/parseAllPatients.sh “\{projname\}” \textgreater{}\textgreater{} /home/processing/logs/whatIsInIDS7/whatIsInIDS7\{projname\}.log 2\textgreater{}\&1 \&\& /home/processing/bin/utils/whatIsInIDS7.py “\{projname\}” \textgreater{}\textgreater{} /home/processing/logs/whatIsInIDS7/whatIsInIDS7\{projname\}.log 2\textgreater{}\&1”

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/getAllPatients2:notes}}
\sphinxAtStartPar
We can provide an argument to this program, the maximum number of days we would like to pull. In general we might get away with a very short period because new scans will come in as recent scans. But some test data migth be very old. So we should do one long run at night and short runs during the day.

\sphinxAtStartPar
As a second argument allow a specific project name.

\sphinxAtStartPar
TODO: This runs too long. Treat some project as special here.

\sphinxstepscope


\subsubsection{heartbeat.sh}
\label{\detokenize{Architecture/scripts/heartbeat:heartbeat-sh}}\label{\detokenize{Architecture/scripts/heartbeat::doc}}
\sphinxAtStartPar
A heartbeat service for the storage class provider running on FIONA. An echoscu will try to contact the local FIONA. If the call fails this script will assume that the service is no longer functioning and kill storectl.sh. This should force a restart with storectl.sh (runs every 10 min).

\sphinxAtStartPar
As a shortcut, instead of actually testing with echoscu the heartbeat will check the last modification time of the storesctl.sh log file. If this file is new heartbeat assumes that the service is still running.


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/heartbeat:notes}}
\sphinxAtStartPar
One way it can fail is if multiple associations are requested. If the timeout happens the connection will be unusable afterwards.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /data/config/config.json,
\sphinxhyphen{} storescpFIONA,

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/heartbeat\$\{projname\}.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file:

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/1 * * * * /usr/bin/nice \sphinxhyphen{}n 3 /var/www/html/server/bin/heartbeat.sh

\end{itemize}

\sphinxstepscope


\subsubsection{parseAllPatients.sh}
\label{\detokenize{Architecture/scripts/parseAllPatients:parseallpatients-sh}}\label{\detokenize{Architecture/scripts/parseAllPatients::doc}}
\sphinxAtStartPar
Populate the WhatIsInIDS7 table in REDCap for a specific project using findscu. This script is part of a sequence of scripts: getAllPatients2.sh \sphinxhyphen{} parseAllPatients.sh \sphinxhyphen{} whatIsInIDS7.py.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /tmp/parseAllPatients\{projname\}/
\sphinxhyphen{} /tmp/pullStudies\{projname\}/

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/whatIsInIDS7\{projname\}.log,

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/whatIsInIDS7\{projname\}.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/48 * * * * /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/getAllPatients2\{projname\}.pid /bin/bash \sphinxhyphen{}c “/home/processing/bin/utils/getAllPatients2.sh 10000 “\{proejct\}” \textgreater{}\textgreater{} /home/processing/logs/whatIsInIDS7/whatIsInIDS7\{projname\}.log 2\textgreater{}\&1 \&\& /home/processing/bin/utils/parseAllPatients.sh “\{projname\}” \textgreater{}\textgreater{} /home/processing/logs/whatIsInIDS7/whatIsInIDS7\{projname\}.log 2\textgreater{}\&1 \&\& /home/processing/bin/utils/whatIsInIDS7.py “\{projname\}” \textgreater{}\textgreater{} /home/processing/logs/whatIsInIDS7/whatIsInIDS7\{projname\}.log 2\textgreater{}\&1”

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/parseAllPatients:notes}}
\sphinxAtStartPar
Depends on output generated by getAllPatients2.sh and provides input for whatIsInIDS7.sh (intermediate processing).

\sphinxAtStartPar
Get list of optional findscu entries from \sphinxurl{http://dicom.nema.org/medical/dicom/current/output/html/part04.html\#sect\_C.6.1.1}

\sphinxstepscope


\subsubsection{populateAutoID.py}
\label{\detokenize{Architecture/scripts/populateAutoID:populateautoid-py}}\label{\detokenize{Architecture/scripts/populateAutoID::doc}}
\sphinxAtStartPar
Check all auto\sphinxhyphen{}id projects and create new transfer requests for each. This functionality will remove the need to use Assign simply based on patient naming convention. Regular safety and quality control phantom scans might use this process to automate the forward of such cases to research PACS.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} REDCap AutoID marked projects

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/populateAutoID.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/populateAutoID.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/1 * * * *  /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/populateAutoID.pid /home/processing/bin/populateAutoID.py \textgreater{}\textgreater{} /home/processing/logs/populateAutoID.log 2\textgreater{}\&1

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/populateAutoID:notes}}
\sphinxAtStartPar
If used projects that are the target of automatic transfers should be regularly screened. Data forwarded on error to such projects should be deleted from research PACS.

\sphinxstepscope


\subsubsection{populateIncoming.py}
\label{\detokenize{Architecture/scripts/populateIncoming:populateincoming-py}}\label{\detokenize{Architecture/scripts/populateIncoming::doc}}
\sphinxAtStartPar
Fills in the Study and Series information in the Incoming table in REDCap. If a CouplingList entry exists its also adding a TransferRequest so that anonymizeAndSend can do its job.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} REDCap Incoming project
\sphinxhyphen{} REDCap project “Projects” routing rules table
\sphinxhyphen{} REDCap CouplingList project

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/populateIncoming.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/populateIncoming.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/1 * * * *  /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/populateIncoming.pid /home/processing/bin/populateIncoming.py \textgreater{}\textgreater{} /home/processing/logs/populateIncoming.log 2\textgreater{}\&1

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/populateIncoming:notes}}
\sphinxAtStartPar
TODO: support a new CouplingList entry even if there is already a TransferRequest done.

\sphinxstepscope


\subsubsection{populateProjects.py}
\label{\detokenize{Architecture/scripts/populateProjects:populateprojects-py}}\label{\detokenize{Architecture/scripts/populateProjects::doc}}
\sphinxAtStartPar
Each study that has been forwarded to PACS should appear in its own REDCap project. Get a list of all transferred studies from REDCaps Incoming project (Transfers table). Get a token for the project and add the entry \sphinxhyphen{} if it does not exist yet. For information to appear in the Imaging instrument set it up as a repeating instrument for “Event 1” (not a repeating event).
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} InstitutionName specific REDCap project (repeating instrument Imaging for “Event 1”)
\sphinxhyphen{} REDCap Projects table of projects with API key

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/populateProjects.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/populateProjects.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/1 * * * *  /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/populateProjects.pid /home/processing/bin/populateProjects.py \textgreater{}\textgreater{} /home/processing/logs/populateProjects.log 2\textgreater{}\&1

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/populateProjects:notes}}
\sphinxAtStartPar
TODO: Without calling for specific projects does not work anymore. We need to get a list of all imaging projects and run them project by project.

\sphinxstepscope


\subsubsection{processSingleFile3.py}
\label{\detokenize{Architecture/scripts/processSingleFile3:processsinglefile3-py}}\label{\detokenize{Architecture/scripts/processSingleFile3::doc}}
\sphinxAtStartPar
Create a daemon process that listens to send messages and reads a DICOM file,
extracts the header information and creates a Study/Series symbolic link structure.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} storectl.sh service storescpFIONA
\sphinxhyphen{} /data/site/raw/
\sphinxhyphen{} /data/site/participants/

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/processSingleFile.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file:

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/10 * * * * /usr/bin/python3 /var/www/html/server/bin/processSingleFile3.py start \textgreater{}\textgreater{} /var/www/html/server/logs/processSingleFile.log 2\textgreater{}\&1

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/processSingleFile3:notes}}\begin{description}
\sphinxlineitem{The parser for the Siemens CSA header have been adapted from}
\sphinxAtStartPar
\sphinxurl{https://scion.duhs.duke.edu/svn/vespa/tags/0\_1\_0/libduke\_mr/util\_dicom\_siemens.py}

\end{description}

\sphinxstepscope


\subsubsection{process\_tiff.sh}
\label{\detokenize{Architecture/scripts/process_tiff:process-tiff-sh}}\label{\detokenize{Architecture/scripts/process_tiff::doc}}
\sphinxAtStartPar
Whole\sphinxhyphen{}slide image file upload the research PACS using the Attach application. The application supports two modes, a DICOM conversion (from wsi) and a direct copy of the wsi\sphinxhyphen{}files to a shared import folder for research PACS.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /ifs/hvn/dma/forskning/pat/forskning\_short/SPIS\_Import/\{projname\}/
\sphinxhyphen{} /var/www/html/applications/Attach/uploads\_done/
\sphinxhyphen{} /var/www/html/applications/Attach/uploads/

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/Pathology\_process\_tiff.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/Pathology\_process\_tiff.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/1 * * * * /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/Pathology\_process\_tiff.pid /var/www/html/applications/Attach/process\_tiff.sh \textgreater{}\textgreater{} /home/processing/logs/Pathology\_process\_tiff.log 2\textgreater{}\&1

\end{itemize}

\sphinxstepscope


\subsubsection{removeOldEntries.sh}
\label{\detokenize{Architecture/scripts/removeOldEntries:removeoldentries-sh}}\label{\detokenize{Architecture/scripts/removeOldEntries::doc}}
\sphinxAtStartPar
The Assign application keeps a jobs file /var/www/html/applications/Assign/incoming.txt around with job entries. This script will remove entries from that list if they are older than 7 days. If studies are send again they will appear again in incoming.txt.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /var/www/html/applications/Assign/incoming.txt

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/removeOldEntries.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/removeOldEntries.pid

\item {} 
\sphinxAtStartPar
start:
2 {\color{red}\bfseries{}*}/4 * * * /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/removeOldEntries.pid /var/www/html/applications/Assign/php/removeOldEntries.sh \textgreater{}\textgreater{} /home/processing/logs/removeOldEntries.log 2\textgreater{}\&1

\end{itemize}


\paragraph{Note}
\label{\detokenize{Architecture/scripts/removeOldEntries:note}}
\sphinxAtStartPar
This will not remove such studies from FIONA, it will only make them inaccessible by Assign. They will be deleted if there is not enough space left on the data partition.

\sphinxstepscope


\subsubsection{resendProject.py}
\label{\detokenize{Architecture/scripts/resendProject:resendproject-py}}\label{\detokenize{Architecture/scripts/resendProject::doc}}
\sphinxAtStartPar
Check all transfer requests (request date and transfer date). Generate transfer requests if the request date is newer than the transfer date.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /home/processing/transfer\_requests/,

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/resendProject.log,

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file:

\item {} 
\sphinxAtStartPar
start:
1 * * * * /home/processing/bin/utils/resendProject.py \textgreater{}\textgreater{} /home/processing/logs/resendProject.log 2\textgreater{}\&1

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/resendProject:notes}}
\sphinxAtStartPar
If run from the command line with the \textendash{}importAll InstitutionName (project name) all transfer requests of this project will get a
new /home/processing/transfer\_requests/ entry regardless of transfer date.

\sphinxstepscope


\subsubsection{runOneJob.sh}
\label{\detokenize{Architecture/scripts/runOneJob:runonejob-sh}}\label{\detokenize{Architecture/scripts/runOneJob::doc}}
\sphinxAtStartPar
Run a single job from the workflow\_joblist.jobs file. The file contains json code per line.

\sphinxAtStartPar
Need to run as user “processing” with flock.
\begin{description}
\sphinxlineitem{Example cron job:}\begin{description}
\sphinxlineitem{/usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/Workflows\_RunOneJob.pid }
\sphinxAtStartPar
/var/www/html/applications/Workflows/php/runOneJob.sh \textgreater{}\textgreater{} /home/processing/logs/Workflows\_RunOneJob.log 2\textgreater{}\&1

\end{description}

\end{description}

\sphinxstepscope


\subsubsection{s2m.sh}
\label{\detokenize{Architecture/scripts/s2m:s2m-sh}}\label{\detokenize{Architecture/scripts/s2m::doc}}
\sphinxAtStartPar
Send to me (s2m). Sends a DICOM directory using the dcmtk docker container from the local machine to the local DICOM node. This script can be used to re\sphinxhyphen{}classify DICOM files (creates /data/site/raw and /data/site/participant information). In rare cases the docker container might not work. In such cases as a fall\sphinxhyphen{}back strategy the systems storescu (DCMTK) executable is used instead.

\sphinxAtStartPar
Usage:
\begin{quote}

\sphinxAtStartPar
\# Send a single directory with DICOM files
s2m.sh \textless{}DICOM directory to send\textgreater{} {[}project{]}

\sphinxAtStartPar
\# Send all studies of a single PatientID
s2m.sh \textless{}PatientID\textgreater{} {[}project{]}

\sphinxAtStartPar
\# send all studies of the last 7 days
s2m.sh last 7 {[}project{]}
\end{quote}
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} storectrl receiver on FIONA (port 11112)
\sphinxhyphen{} /data/config/config.json

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file:

\item {} 
\sphinxAtStartPar
start: manually

\end{itemize}

\sphinxstepscope


\subsubsection{sendFiles.sh}
\label{\detokenize{Architecture/scripts/sendFiles:sendfiles-sh}}\label{\detokenize{Architecture/scripts/sendFiles::doc}}
\sphinxAtStartPar
Example crontab entry that starts this script every 30 minutes

\begin{sphinxVerbatim}[commandchars=\\\{\}]
*/30 * * * * /usr/bin/nice \PYGZhy{}n 3 /var/www/html/server/bin/sendFiles.sh
\end{sphinxVerbatim}

\sphinxAtStartPar
Add the above line to your machine using:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZgt{}\PYG{+w}{ }crontab\PYG{+w}{ }\PYGZhy{}e
\end{sphinxVerbatim}

\sphinxAtStartPar
This script is supposed to send compressed data files for DICOM and k\sphinxhyphen{}space to the DAIC endpoint using sftp. All data in the /data/outbox directory will be send using local and DAIC md5sum files.

\sphinxstepscope


\subsubsection{storectl.sh}
\label{\detokenize{Architecture/scripts/storectl:storectl-sh}}\label{\detokenize{Architecture/scripts/storectl::doc}}
\sphinxAtStartPar
Start the service class provider (SCP) for the storage service class. DICOM files received this way will be stored in /data/site/archive/. This service will also announce each incoming image to processSingleFile3.py using a pipe. Processed files will appear in /data/site/raw and /data/site/participant as symbolic link sorted by study/patient and image series with JSON summary files on a series level.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /data/config/config.json,
\sphinxhyphen{} storescpFIONA,
\sphinxhyphen{} receiveSingleFile.sh,
\sphinxhyphen{} processSingleFile3.py,
\sphinxhyphen{} heartbeat.sh will try to contact the DICOM listener and restart this service in case of error

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/storescpd\$\{projname\}.log,
\sphinxhyphen{} \$\{SERVERDIR\}/logs/storescpd\sphinxhyphen{}start.log

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/storescpd\$\{projname\}.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/10 * * * * env USER=\$LOGNAME /var/www/html/server/bin/storectl.sh start \textgreater{}\textgreater{} /var/www/html/server/logs/storectl.log 2\textgreater{}\&1

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/storectl:notes}}
\sphinxAtStartPar
This system service will stop if a control file /data/enabled exists and its first character is a “0”.

\sphinxstepscope


\subsubsection{whatIsInIDS7.py}
\label{\detokenize{Architecture/scripts/whatIsInIDS7:whatisinids7-py}}\label{\detokenize{Architecture/scripts/whatIsInIDS7::doc}}
\sphinxAtStartPar
Populate the WhatIsInIDS7 table in REDCap for a specific project using findscu. This script is part of a sequence of scripts: getAllPatients2.sh \sphinxhyphen{} parseAllPatients.sh \sphinxhyphen{} whatIsInIDS7.py.
\begin{itemize}
\item {} 
\sphinxAtStartPar
user: processing

\item {} 
\sphinxAtStartPar
depends\sphinxhyphen{}on:
\sphinxhyphen{} /tmp/parseAllPatients\{projname\}/
\sphinxhyphen{} /tmp/pullStudies\{projname\}/

\item {} 
\sphinxAtStartPar
log\sphinxhyphen{}file:
\sphinxhyphen{} \$\{SERVERDIR\}/logs/whatIsInIDS7\{projname\}.log,

\item {} 
\sphinxAtStartPar
pid\sphinxhyphen{}file: \$\{SERVERDIR\}/.pids/whatIsInIDS7\{projname\}.pid

\item {} 
\sphinxAtStartPar
start:
{\color{red}\bfseries{}*}/48 * * * * /usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/getAllPatients2\{projname\}.pid /bin/bash \sphinxhyphen{}c “/home/processing/bin/utils/getAllPatients2.sh 10000 “\{proejct\}” \textgreater{}\textgreater{} /home/processing/logs/whatIsInIDS7/whatIsInIDS7\{projname\}.log 2\textgreater{}\&1 \&\& /home/processing/bin/utils/parseAllPatients.sh “\{projname\}” \textgreater{}\textgreater{} /home/processing/logs/whatIsInIDS7/whatIsInIDS7\{projname\}.log 2\textgreater{}\&1 \&\& /home/processing/bin/utils/whatIsInIDS7.py “\{projname\}” \textgreater{}\textgreater{} /home/processing/logs/whatIsInIDS7/whatIsInIDS7\{projname\}.log 2\textgreater{}\&1”

\end{itemize}


\paragraph{Notes}
\label{\detokenize{Architecture/scripts/whatIsInIDS7:notes}}
\sphinxAtStartPar
TODO: check if the number of study related series is correct (looks too large in Export app), seems to depend on \textendash{}repeat findscu.

\sphinxstepscope


\subsubsection{whatIsNotInIDS7.py}
\label{\detokenize{Architecture/scripts/whatIsNotInIDS7:whatisnotinids7-py}}\label{\detokenize{Architecture/scripts/whatIsNotInIDS7::doc}}
\sphinxAtStartPar
There is no docstring.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/anonymizeAndSend::doc}]{\sphinxcrossref{\DUrole{doc}{anonymizeAndSend.py}}}} \sphinxhyphen{} Processes imaging studies, performs anonymization, and sends them to research PACS

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/clearExports::doc}]{\sphinxcrossref{\DUrole{doc}{clearExports.sh}}}} \sphinxhyphen{} Removes old export files when storage reaches capacity thresholds

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/clearOldFiles::doc}]{\sphinxcrossref{\DUrole{doc}{clearOldFiles.sh}}}} \sphinxhyphen{} Removes old studies from \sphinxcode{\sphinxupquote{/data/site/archive}} when disk usage exceeds 80\%

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/clearStaleLinks::doc}]{\sphinxcrossref{\DUrole{doc}{clearStaleLinks.sh}}}} \sphinxhyphen{} Removes broken symbolic links and empty directories from data structures

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/createTransferRequests::doc}]{\sphinxcrossref{\DUrole{doc}{createTransferRequests.py}}}} \sphinxhyphen{} Generates transfer requests for studies that need anonymization and forwarding to research projects

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/createTransferRequestsForProcessed::doc}]{\sphinxcrossref{\DUrole{doc}{createTransferRequestsForProcessed.py}}}} \sphinxhyphen{} Handles transfer requests for processed/derived imaging data from workstations back to research PACS

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/createZipFileCmd::doc}]{\sphinxcrossref{\DUrole{doc}{createZipFileCmd.php}}}} \sphinxhyphen{}  Creates anonymized ZIP archives for research data distribution

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/cron::doc}]{\sphinxcrossref{\DUrole{doc}{cron.sh}}}} \sphinxhyphen{} Processes trigger\sphinxhyphen{}action pairs from JSON configuration files for event\sphinxhyphen{}driven automation

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/getAllPatients2::doc}]{\sphinxcrossref{\DUrole{doc}{getAllPatients2.sh}}}} \sphinxhyphen{} Retrieves patient and study information from research PACS using findscu

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/heartbeat::doc}]{\sphinxcrossref{\DUrole{doc}{heartbeat.sh}}}} \sphinxhyphen{} Checks DICOM service responsiveness and restarts failed components

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/parseAllPatients::doc}]{\sphinxcrossref{\DUrole{doc}{parseAllPatients.sh}}}} \sphinxhyphen{} Parses patient data retrieved by getAllPatients2.sh and extracts study\sphinxhyphen{}level metadata for REDCap import

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/populateAutoID::doc}]{\sphinxcrossref{\DUrole{doc}{populateAutoID.py}}}} \sphinxhyphen{}  Generates automatic participant IDs for projects using pseudonymized identifiers

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/populateIncoming::doc}]{\sphinxcrossref{\DUrole{doc}{populateIncoming.py}}}} \sphinxhyphen{} Processes incoming DICOM studies and creates metadata records in REDCap

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/populateProjects::doc}]{\sphinxcrossref{\DUrole{doc}{populateProjects.py}}}} \sphinxhyphen{} Populates individual research project databases with distributed data

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/processSingleFile3::doc}]{\sphinxcrossref{\DUrole{doc}{processSingleFile3.py}}}} \sphinxhyphen{} Extracts metadata from DICOM files and creates directory structures

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/process_tiff::doc}]{\sphinxcrossref{\DUrole{doc}{process\_tiff.sh}}}} \sphinxhyphen{} Converts whole slide imaging (WSI) files to DICOM format for pathology processing

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/removeOldEntries::doc}]{\sphinxcrossref{\DUrole{doc}{removeOldEntries.sh}}}} \sphinxhyphen{} Removes old entries from incoming data tracking files

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/resendProject::doc}]{\sphinxcrossref{\DUrole{doc}{resendProject.py}}}} \sphinxhyphen{} Handles re\sphinxhyphen{}transmission of studies when initial transfers fail or new data arrives

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/runOneJob::doc}]{\sphinxcrossref{\DUrole{doc}{runOneJob.sh}}}} \sphinxhyphen{} Processes containerized analysis jobs from job queue

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/s2m::doc}]{\sphinxcrossref{\DUrole{doc}{s2m.sh}}}} \sphinxhyphen{} Re\sphinxhyphen{}sends DICOM directories through the processing pipeline for re\sphinxhyphen{}classification

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/sendFiles::doc}]{\sphinxcrossref{\DUrole{doc}{sendFiles.sh}}}} \sphinxhyphen{} Uploads anonymized data to external research repositories via secure file transfer

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/storectl::doc}]{\sphinxcrossref{\DUrole{doc}{storectl.sh}}}} \sphinxhyphen{} Manages the main DICOM C\sphinxhyphen{}STORE receiver daemon

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/whatIsInIDS7::doc}]{\sphinxcrossref{\DUrole{doc}{whatIsInIDS7.py}}}}\sphinxhyphen{} Catalogs all studies present in the research imaging database

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Architecture/scripts/whatIsNotInIDS7::doc}]{\sphinxcrossref{\DUrole{doc}{whatIsNotInIDS7.py}}}}\sphinxhyphen{} Identifies and removes database entries for studies no longer in PACS

\end{enumerate}


\chapter{Contact Information}
\label{\detokenize{index:contact-information}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Website: \sphinxurl{https://fiona.ihelse.net}

\item {} 
\sphinxAtStartPar
Location: Haukeland University Hospital, Bergen, Norway

\end{itemize}


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\DUrole{xref}{\DUrole{std}{\DUrole{std-ref}{genindex}}}

\item {} 
\sphinxAtStartPar
\DUrole{xref}{\DUrole{std}{\DUrole{std-ref}{modindex}}}

\item {} 
\sphinxAtStartPar
\DUrole{xref}{\DUrole{std}{\DUrole{std-ref}{search}}}

\end{itemize}



\renewcommand{\indexname}{Index}
\printindex
\end{document}