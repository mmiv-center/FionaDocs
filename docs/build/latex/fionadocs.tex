%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Learn}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{FionaDocs}
\date{Jul 28, 2025}
\release{}
\author{Hauke Bartsch, Marek Kociński}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxAtStartPar
FIONA (Flash\sphinxhyphen{}based Input/Output Network Appliance) \sphinxhyphen{} A secure research data gateway for medical imaging. Provides DICOM anonymization, quarantine management, and automated transfer from clinical to research PACS systems while ensuring GDPR compliance.

\sphinxstepscope


\chapter{EndUser}
\label{\detokenize{EndUser/index:enduser}}\label{\detokenize{EndUser/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} Doctors, researchers, medical personnel

\sphinxstepscope


\section{How to apply to the Research Information System Helse Vest}
\label{\detokenize{EndUser/end-user:how-to-apply-to-the-research-information-system-helse-vest}}\label{\detokenize{EndUser/end-user::doc}}

\subsection{1. Project creation, setup and access}
\label{\detokenize{EndUser/end-user:project-creation-setup-and-access}}
\sphinxAtStartPar
In order to apply for a new project on the research information system (research PACS)
please fill out the application form available under “Apply/Apply for a new research project”
here: \sphinxurl{https://www.google.com} or \sphinxurl{ttps://fiona.medtek.hbe.med.nvsl.no/}.

\sphinxAtStartPar
Additional user access can be requested by the principal investigator of the project under
“Apply/Apply for access to an existing project”.

\sphinxAtStartPar
If you encounter any problems with applying for access, contact \sphinxhref{mailto:Hauke.Bartsch@helse-bergen.no}{Hauke.Bartsch@helse\sphinxhyphen{}bergen.no}.


\subsection{2. Access to REDCap for structured data}
\label{\detokenize{EndUser/end-user:access-to-redcap-for-structured-data}}
\sphinxAtStartPar
Our project uses REDCap as an electronic data capture solution. Projects on the research information system can receive access to their REDCap project as well as access to the image data viewing (see next section).


\subsection{3. Access to the “Sectra DMA Forskning” research PACS viewer}
\label{\detokenize{EndUser/end-user:access-to-the-sectra-dma-forskning-research-pacs-viewer}}
\sphinxAtStartPar
Access to the image data is provided by IKT. Such access requires a valid Haukeland University Hospital user account and a laptop or PACS workstation that is under control of IKT. If you contact IKT ask for the start menu item “Sectra DMA Forskning”. With the program and your hospital username and password you will gain access to the research picture archive and communication system (PACS).

\sphinxAtStartPar
Without access to a specific research project you will not see any data in the research PACS. Each research projects requires specific permissions to become accessible for a user.

\sphinxAtStartPar
The research PACS viewer is using a separate clinical PACS software installation (Sectra IDS7). In order to prevent possible interactions between the clinical and the research PACS only one of the application can run at a given time. You will be logged out of the clinical PACS if you start the research PACS viewer.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=268\sphinxpxdimen,height=451\sphinxpxdimen]{{ikt-sectra-dma-forskning}.png}
\caption{Forskning PACS start menu icon required to view image data by project.}\label{\detokenize{EndUser/end-user:id2}}\end{figure}


\subsection{4. Submit data to the Research Information System}
\label{\detokenize{EndUser/end-user:submit-data-to-the-research-information-system}}
\sphinxAtStartPar
Overview: The research information system contains two components. Image data is stored in the Sectra DMA Forskning \sphinxhyphen{} an image viewer with a vendor neutral archive (VNA). All meta\sphinxhyphen{}data is stored in table format in an electronic data capture system (REDCap). Sending image data will create the appropriate entries in REDCap. Additional data collection instruments can be set up there and used to capture assessments, consent/assent and results from automated image processing. All image data is assigned to a project to allow for project specific data views for each research information user.

\sphinxAtStartPar
The basic steps to submit data are:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Send DICOM studies to “HBE Fiona” or “Fiona” (modality station)

\item {} 
\sphinxAtStartPar
Assign to project on \sphinxurl{https://fiona.medtek.hbe.med.nvsl.no/applications/Assign/}

\end{enumerate}

\sphinxAtStartPar
In step 1 data arrives in a \sphinxstylestrong{quarantine} location. In step 2 each DICOM study needs to be \sphinxstylestrong{assigned to project}, pseudonymized participant identifier and event name before it will be forwarded to the research PACS and becomes visible to the project users.


\subsubsection{4.1 Setup of a new project}
\label{\detokenize{EndUser/end-user:setup-of-a-new-project}}
\sphinxAtStartPar
The project needs to exist on the research information system before participant data is collected. After a successful setup your project and event names should appear in the Assign application.


\subsubsection{4.2 How to add image data}
\label{\detokenize{EndUser/end-user:how-to-add-image-data}}
\sphinxAtStartPar
The end\sphinxhyphen{}point for images is FIONA (\sphinxurl{https://fiona.ihelse.no}):
\begin{itemize}
\item {} 
\sphinxAtStartPar
AETitle: FIONA

\item {} 
\sphinxAtStartPar
IP: 10.94.209.30

\item {} 
\sphinxAtStartPar
Port: 11112

\end{itemize}

\sphinxAtStartPar
Images that arrive at this endpoint are added to a quarantine system (FIONA, \sphinxurl{https://fiona.medtek.hbe.med.nvsl.no:4444}) running the REDCap software. Automatic routing rules (stored in REDCap) are used to anonymize and forward the data to the image storage. If such routing has not been set up the “Assign” application (see below) needs to be used to forward individual studies based on pre\sphinxhyphen{}existing patient ID lists.

\sphinxAtStartPar
From Sectra Production you can send image data to the endpoint “HBE Fiona”. Modality stations might also have the “FIONA” endpoint setup. If the data is already anonymized and has a de\sphinxhyphen{}identified PatientName/PatientID entry that indicates the project the FIONA system will attempt to de\sphinxhyphen{}identify (pseudonymization) further DICOM tags and forward the images to IDS7 (may take minutes). No further action is needed. If you suspect this did not work, see the corresponding section about the representation of transfers in REDCap.

\sphinxAtStartPar
Image data that contains patient information cannot be automatically assigned to the appropriate project as there is only a single endpoint for FIONA shared by all projects. To assign participants correctly to projects and de\sphinxhyphen{}identified participant identifiers a user can perform the assignment to project, participant ID and event name in the “Assign” web application.

\sphinxAtStartPar
If the participant identifiers do not exist yet user may add new project specific identifiers in “Assign”. Such identifiers need to follow the naming rules for a project and are verified using regular expression pattern specific for each project.

\sphinxAtStartPar
The web application for the assignment of scans forwarded to HBE Fiona is available at:
\sphinxurl{https://fiona.medtek.hbe.med.nvsl.no/applications/Assign/}

\sphinxAtStartPar
On the Assign website look for your forwarded study. It should appear in about 15 min.
Identify the correct scan using the Accession Number (Undersøkelse\sphinxhyphen{}ID) or the date and time
of the scan. Select your project from the drop\sphinxhyphen{}down. This will fill in the list of patient names
and event names. Select the correct patient name and the event this study belongs to. After
a couple of seconds a new button appears below the study entry. Use it to select and
confirm the assignment. This will forward a de\sphinxhyphen{}identified version of the study data to “Sectra
Forskning”. If you do not assign your data on Assign they will not be forwarded. After a
couple of days (7 days) such data will disappear from the list. Send an email to Hauke to request
a resend.


\subsubsection{4.2.1 Verification steps}
\label{\detokenize{EndUser/end-user:verification-steps}}
\sphinxAtStartPar
After data arrived at the research PACS a verification step should ensure that all images have been received at the quarantine on FIONA and have been forwarded to research PACS. This can be done by comparing the number of images on the sending station with the number of images in IDS7.

\sphinxAtStartPar
Furthermore the import step will also attempt to de\sphinxhyphen{}identify secondary capture images with burned in image information. This process is fully automated and can result in false positive and occasionally false negative results. After a review of the data in IDS7 the user may decide which secondary image series are “safe” to exclude from the pixel rewriting on import. For example a secondary capture series from DTI may not contain any burned in names or identifying numbers or dates. Such image series can be removed in REDCap from further pixel anonymization.

\sphinxAtStartPar
If the number of images on FIONA does not correspond to the number of images available cache previous assignments and automatically forward such images to the research PACS using the reviously defined project, patient identifier and event name.


\subsection{5. Export image data from research PACS}
\label{\detokenize{EndUser/end-user:export-image-data-from-research-pacs}}
\sphinxAtStartPar
Data in the research PACS is secured by generic procedures during data import that delete or rewrite some DICOM tags, changes dates and replaces unique identifiers. A documentation of this process is available on the GitHub repository of the projects for removal of DICOM meta\sphinxhyphen{}tags:
\sphinxurl{https://github.com/mmiv-center/DICOMAnonymizer}, and for the removal of burned in image information: \sphinxurl{https://github.com/mmiv-center/RewritePixel}.

\sphinxAtStartPar
Data stored in the research PACS is therefore in general suited for data sharing IF pseudonymized data is allowed. In order to support users with the task of data pseudonymization the research information system provides the “Review” web application that lists all existing DICOM tags in a research project (\sphinxurl{https://fiona.ihelse.net}).

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Pseudonymized data is defined here as data for which a coupling list exists somewhere in the universe. This is in contrast to anonymized data where such a list does not exist and can also not be created.
\end{sphinxadmonition}

\sphinxAtStartPar
Further de\sphinxhyphen{}identification procedures might require changes to image data such as face stripping, removal of outer ear tissue, cortical folding pattern, etc.. Such potential sources of information for re\sphinxhyphen{}identification have been proposed in the literature but actual attacks based on them have not recently been documented. Better documented and perhaps more relevant are re\sphinxhyphen{}identification using spreadsheet data where external sources are linked to the projects data to discover the supposedly hidden identity of the research participants. For example it might be possible to link Gender, day of birth and the hospital name to a real participant name using a birth or voting registry.


\subsubsection{5.1 Export using IDS7}
\label{\detokenize{EndUser/end-user:export-using-ids7}}
\sphinxAtStartPar
The image data from a study can be exported from the research PACS using a right\sphinxhyphen{}click menu entry available in the Informasjonsvindu “Exporter til medium”. Such exports will generate either a derived patient ID \textendash{} if an Anonymization Profile is selected or a faithful copy of the data with all pseudonymized DICOM tags intact.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
This export does not prevent re\sphinxhyphen{}identification. Specifically the PatientID field is created from the pseudonymized ID used in the research PACS and therefore not random.
\end{sphinxadmonition}

\sphinxAtStartPar
The export is also case\sphinxhyphen{}by\sphinxhyphen{}case, which is tedious if many data need to be exported. The export will also result in directory names that do not reflect the research project structure as participant identifier \textendash{} event name \textendash{} modality \textendash{} image series. It may be advantageous to export from IDS7 if a single image study needs to be shared without special requirements. Such export folders will also contain an image viewer.


\subsubsection{5.2 Export to project specific formats, NIfTI and zip\sphinxhyphen{}files}
\label{\detokenize{EndUser/end-user:export-to-project-specific-formats-nifti-and-zip-files}}
\sphinxAtStartPar
The research information system supports a separate export facility that is more suited to implement project specific de\sphinxhyphen{}identification. Such export requirements include specific DICOM value changes (replacing underscores with dashes), adding birth date information back, formatting and cleaning of series descriptions, zip\sphinxhyphen{}file exports with specific folder structures etc.. This export is appropriate if the receiving institution has specific requirements on how data should be shared.

\sphinxAtStartPar
Request access to the specialized data exports for your project from \sphinxhref{mailto:Hauke.Bartsch@helse-bergen.no}{Hauke.Bartsch@helse\sphinxhyphen{}bergen.no}. Provide your export specification and we will implement your anonymization scheme and make it available to you and other researchers. As an example the “Export” application currently supports the export in NIfTI formats (using dcm2niix) and the export in several zip\sphinxhyphen{}file formats.


\subsection{6. Research Information System}
\label{\detokenize{EndUser/end-user:research-information-system}}
\sphinxAtStartPar
The research information system (RIS) of the Western Norway Health Authorities (Helse\sphinxhyphen{}Vest) also called the “Steve Project” is a secure computer system that stores research data for approved research projects at Haukeland University Hospital and connected hospitals of the Helse Vest region. The project is supported by the radiology department of Haukeland University Hospital and the Mohn Medical Imaging and Visualization Center and approved for research project use by IKT Helse Vest. The physical location of the data is at the premises of IKT Helse Vest Norway. Dedicated storage area and research software (Sectra, IDS7) provides researchers with appropriate permission access to their data. All data is stored in a de\sphinxhyphen{}identified format inside the RIS. Maintaining a coupling list is the responsibility of each project and not part of the functionality of the RIS.

\sphinxAtStartPar
Based on the REK/DIPA rules for each project a lifetime tracking of the research data per project ensures that data can be anonymized based on data sharing requirements, and that data can be deleted at the end of the project phase \sphinxhyphen{} if required. We suggest that research data is allowed to be fully anonymized at the end of the project and remain in RIS for general research access.

\sphinxAtStartPar
Key features of the RIS include:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Hosted side\sphinxhyphen{}by\sphinxhyphen{}side with the clinical PACS as an independent installation.

\item {} 
\sphinxAtStartPar
Accepts de\sphinxhyphen{}identified patient identifiers only.

\item {} 
\sphinxAtStartPar
All data is moved through a de\sphinxhyphen{}identification process upon import into RIS.

\item {} 
\sphinxAtStartPar
All data is assigned to one or more specific research projects and the visibility of data is restricted to individuals with project role access rights.

\item {} 
\sphinxAtStartPar
Projects require a valid REK approval, such documentation has to be provided at the start of a project by the project owner.

\item {} 
\sphinxAtStartPar
The project owner can identify additional user accounts that can access the data.

\item {} 
\sphinxAtStartPar
User access to the research PACS is controlled by IKT and requires a valid Haukeland University Hospital user account.

\end{itemize}

\sphinxstepscope


\chapter{Admin}
\label{\detokenize{ServerAdmin/index:admin}}\label{\detokenize{ServerAdmin/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} IT administrators, DevOps

\sphinxstepscope


\section{End\sphinxhyphen{}user contract}
\label{\detokenize{ServerAdmin/admin:end-user-contract}}\label{\detokenize{ServerAdmin/admin::doc}}
\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
The following text is from the Apply website for the Steve system. Please check this page for updates to the wording.
\end{sphinxadmonition}

\sphinxAtStartPar
By creating a project on the research information system you agree to the following:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
All data stored in the RIS belongs to the research project owner represented by the PI of the project. Adding and verifying added data to the RIS is the responsibility of the project owner. The RIS team will help research projects to automate this process.

\end{enumerate}

\sphinxAtStartPar
2. Sensitive participant information needs to be stored under a separate account and needs to be accessible to authorized (data\sphinxhyphen{}manager and above) user accounts only. All other research data is stored as de\sphinxhyphen{}identified data (pseudonymized, with external coupling list) or in an anonymized format. This restriction includes sensitive information such as Norwegian identification numbers, real names or parts of real names, other birth certificate information and initials. It is the responsibility of the project to review the result of the de\sphinxhyphen{}identification procedures implemented by the RIS team on image meta\sphinxhyphen{}data using \sphinxurl{https://fiona.medtek.hbe.med.nvsl.no/applications/ReviewDICOMTags} and the result of the detection and removal of burned in image data (IDS7). The project will inform the RIS team in a timely manner if the
pseudonymization procedure of the RIS team needs to be updated. This restriction is in place to allow for the largest possible user base for the RIS including PhD students and external collaborators.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
All research data is stored as part of RIS projects identified by a project name of 5\sphinxhyphen{}20 characters. Users can gain access to the data upon request from the project PI or an appointed representative of the PI.

\item {} 
\sphinxAtStartPar
Projects are expected to utilize best\sphinxhyphen{}practises for data handling such as accounts based on roles like data\sphinxhyphen{}entry (add data only) and data\sphinxhyphen{}manager (change data, export data). Personally identifying fields have to be marked as such (Identifier? field of the instrument designer) and data access groups shall be used for multi\sphinxhyphen{}site project setups.

\item {} 
\sphinxAtStartPar
Projects will undergo a short review from the RIS team before they are moved by the RIS team from development mode into production mode for data capture. This review may generate suggestions for the project on how to implement best practices for longitudinal data captures, missing validation and the use of additional software features. All research data is collected and stored with a valid REK approval for the time period specified in the REK approval. The REK approval is required at the time that the RIS project is created. Any change of the REK approval start and end dates need to be reported to the RIS team. At the end of the project period data can be either: a) deleted or  b) fully anonymized (suggested choice). It is up to the project to inform the RIS team about the correct way of handling the data at the end of the project. By default we will assume that data needs to be deleted. Based on the project end date (REK) the RIS team will inform the PI of the project of a pending change of the project status to the archive state. An archive state project will not allow for further data entry, or changes to captured data. After a period of about 1 year the project data will be exported and provided to the project PI for download. An archived project can be deleted by the RIS team after an unspecified time period. If the project data can be fully anonymized, the RIS team may create a copy of the data with new participant identifiers (without a coupling list). After a re\sphinxhyphen{}import a fully anonymized version of the project data can become accessible to other RIS users. The original project data will change to archive state, a copy is provided to the projects PI and the data can be deleted by the RIS team after about 1 year.

\end{enumerate}


\section{Features for data migration}
\label{\detokenize{ServerAdmin/admin:features-for-data-migration}}
\sphinxAtStartPar
The Assign web\sphinxhyphen{}application allows users to upload a coupling list that maps the accession number (Undersøkelse\sphinxhyphen{}ID) of the study to the pseudonymized participant identifier. Such mappings must be uploaded before the first image study of the project has been forwarded to FIONA. Incoming DICOM studies in FIONA that match entries in the coupling list will automatically be assigned to the project.


\section{How to handle errors?}
\label{\detokenize{ServerAdmin/admin:how-to-handle-errors}}
\sphinxAtStartPar
Correcting errors during data import are not difficult to fix. Try to follow up on such errors on an ongoing basis. The quarantine FIONA station may have still have a copy of the data in its cache which simplifies the process. Contact \sphinxhref{mailto:Hauke.Bartsch@helse-bergen.no}{Hauke.Bartsch@helse\sphinxhyphen{}bergen.no} in such cases and ask for help. This will allow you to fix issues such as:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Wrong assignment of participant identifiers to DICOM studies

\item {} 
\sphinxAtStartPar
Wrong assignment of event names to DICOM studies

\item {} 
\sphinxAtStartPar
Missing images or image series for existing DICOM studies

\item {} 
\sphinxAtStartPar
Missing entries for DICOM studies on “Assign”

\end{itemize}


\section{Export to project specific formats, NIfTI and zip\sphinxhyphen{}files}
\label{\detokenize{ServerAdmin/admin:export-to-project-specific-formats-nifti-and-zip-files}}
\sphinxAtStartPar
The research information system supports a separate export facility that is more suited to implement project specific de\sphinxhyphen{}identification. Such export requirements include specific DICOM value changes (replacing underscores with dashes), adding birth date information back, formatting and cleaning of series descriptions, zip\sphinxhyphen{}file exports with specific folder structures etc.. This export is appropriate if the receiving institution has specific requirements on how data should be shared.

\sphinxAtStartPar
Request access to the specialized data exports for your project from \sphinxhref{mailto:Hauke.Bartsch@helse-bergen.no}{Hauke.Bartsch@helse\sphinxhyphen{}bergen.no}. Provide your export specification and we will implement your anonymization scheme and make it available to you and other researchers. As an example the “Export” application currently supports the export in NIfTI formats (using dcm2niix) and the export in several zip\sphinxhyphen{}file formats.


\section{Sensitive Data Projects \textendash{} Separation of Sensitive Information and Data}
\label{\detokenize{ServerAdmin/admin:sensitive-data-projects-separation-of-sensitive-information-and-data}}
\sphinxAtStartPar
A sensitive data project is one that is used to capture human subject data and in general will require a REK (regional ethics board approval). In order to setup such a project in REDCap we suggest the follow structure and features of REDCap to be used. These recommendations have been generated based on discussions in relevant risk assessments.

\sphinxAtStartPar
All sensitive data should be stored in a separate REDCap “ID” project including Norwegian Identification Numbers, names or parts of names, addresses and full birth dates (see Figure 1). This project should have its own roles of “Data Manager”, “Data Entry”, and “Controller”.  eople with permission to access and/or edit this information can use this database to keep contact information up\sphinxhyphen{}to\sphinxhyphen{}date and to enroll new participants into the study. Each participant should be assigned a pseudonymized ID in the sensitive data project that links the entry to the corresponding participant in the data project. Examples for this ID are: \textless{}project name\textgreater{}\sphinxhyphen{}\textless{}site number\textgreater{}\sphinxhyphen{}0001, \textless{}project name\textgreater{}\sphinxhyphen{}\textless{}site number\textgreater{}\sphinxhyphen{}0002, etc..

\sphinxAtStartPar
All other data should be stored in a separate REDCap “Data” project using the pseudonymized participant ID as a “record\_id” (first field in the study).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{redcap-sensitive-data}.png}
\caption{Sensitive data projects should be split into a REDCap project for data (using pseudonymized ids) and a REDCap project for sensitive data including the coupling list.}\label{\detokenize{ServerAdmin/admin:id1}}\end{figure}


\subsection{User rights management}
\label{\detokenize{ServerAdmin/admin:user-rights-management}}
\sphinxAtStartPar
When a project leader / principal investigator (PI) is given a REDCap account and project, they are given “project owner” roles. The project owner can then provide access to project members in “roles”. A role defines a given set of custom permissions which defines the user’s access to data, export permissions and ability to make changes to data.

\sphinxAtStartPar
Each project can have predefined roles. We recommend the predefined roles “Data Manager” (ability to change study design, export), “Data Entry” (add, change, or delete data) and “Controller” to define roles for data viewing, editing, and deleting records. In more complex cases, different access settings can be given on different forms in the study (see also API access with REDCap). Individual users are assigned to project roles as part of gaining access to one project.

\sphinxAtStartPar
The user rights management is the responsibility of the project owner and/or the users they add to the project with User Rights access. User roles should be set at the lowest access level that is necessary (e.g., export rights only for users who need this permission). Access to the project should be reviewed regularly and personnel who no longer require access need to be removed from the project.


\subsection{User rights \textendash{} multi\sphinxhyphen{}center projects}
\label{\detokenize{ServerAdmin/admin:user-rights-multi-center-projects}}
\sphinxAtStartPar
In a project where several institutions participate with their own project participants (several hospitals etc.) each group of participants should be assigned to a separate “data access group”. This functionality allows records in a study to be part of the user rights management. A user with access to a single data access group can only see participants that belong to this group. If this user creates a new participant, they will be automatically assigned to the group.


\subsection{How to handle Email Addresses in Data Projects}
\label{\detokenize{ServerAdmin/admin:how-to-handle-email-addresses-in-data-projects}}
\sphinxAtStartPar
Email addresses are special identifying fields that can be stored in data projects for the purpose of creating automated invites for participants to fill out forms from home. In projects that use this feature email fields need to be present in the data project in order to allow for email distribution to participants.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Add such email fields to a separate instrument of the REDCap data project and mark the instrument as viewable by specific roles only (like Data Managers).

\item {} 
\sphinxAtStartPar
Mark the email field as an “Identifier” field to prevent export of the field’s data by user  of roles that cannot view sensitive fields.

\item {} 
\sphinxAtStartPar
Add the Action Tag “@PASSWORDMASK” to the field to prevent accidental viewing of the fields values if the instrument is displayed on screen.

\item {} 
\sphinxAtStartPar
Add a field validation as “Email” to prevent some miss\sphinxhyphen{}typing of emails.

\end{enumerate}


\subsection{Automatic data exports from REDCap}
\label{\detokenize{ServerAdmin/admin:automatic-data-exports-from-redcap}}
\sphinxAtStartPar
Data may be exported from REDCap using the REDCap API, a technical interface to automate the export of project and participant information using scripting. To provide such access a dedicated user\sphinxhyphen{}account “api\_\textless{}real username\textgreater{}” should be created which is specific for a single project. Configure the account with a limited set of read permissions to specific fields or instruments using a new API role. The REDCap API will borrow these restrictive permissions for controlled access.

\sphinxAtStartPar
Setup: An administrator can generate an API “token” for this account and share the token and examples of accessing the resource (curl\sphinxhyphen{}based access) with the user.

\sphinxAtStartPar
Any change in the role of the \textless{}real username\textgreater{} should also apply to the connected API account. Specifically loosing access to the project should be implemented for both \textless{}real username\textgreater{} and api\_\textless{}real username\textgreater{}.


\subsection{Steps at the end of a REDCap project}
\label{\detokenize{ServerAdmin/admin:steps-at-the-end-of-a-redcap-project}}
\sphinxAtStartPar
REDCap is a tool for data collection. At the end of data capture projects using REDCap receive a notification of study end. At this point projects may provide updated REK information(extension of data capture notice). If no such notice is received REDCap projects will:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Lock all data participants (no further update/add).

\item {} 
\sphinxAtStartPar
Provide a copy of the REDCap project (CDISC format) to the project’s principal investigator or delegate.

\item {} 
\sphinxAtStartPar
Provide a copy of the project data (CSV) and data dictionary (PDF) to the principal investigator or delegate.

\item {} 
\sphinxAtStartPar
Request a confirmation that project data (CDISC and CSV) have been received by the project.

\item {} 
\sphinxAtStartPar
Permanently delete all project data.

\end{itemize}

\sphinxAtStartPar
This process will be documented in the REDCap project tracking project “DataTransferProjects”, the project management tool with information on identity of the person requesting project removal and confirmations for all steps of the project removal process.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{redcap-end-of-project}.png}
\caption{End\sphinxhyphen{}of\sphinxhyphen{}project tracking for REDCap projects}\label{\detokenize{ServerAdmin/admin:id2}}\end{figure}

\sphinxstepscope


\chapter{Architecture, data flow and system components}
\label{\detokenize{Architecture/index:architecture-data-flow-and-system-components}}\label{\detokenize{Architecture/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} Developers, system architects

\sphinxstepscope


\section{Architecture Overview}
\label{\detokenize{Architecture/overview:architecture-overview}}\label{\detokenize{Architecture/overview::doc}}
\sphinxAtStartPar
Diagram of Fiona system architecture including: network layer, processing layer, storage layer, transfer layer and management layer

\sphinxincludegraphics{mermaid-94594455523aa3be4337fc237078760eebe786db.pdf}


\subsection{System Purpose}
\label{\detokenize{Architecture/overview:system-purpose}}
\sphinxAtStartPar
FIONA serves as an intermediary system that:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Receives medical image data from clinical PACS systems

\item {} 
\sphinxAtStartPar
Processes and classifies incoming DICOM studies

\item {} 
\sphinxAtStartPar
Anonymizes data according to research requirements

\item {} 
\sphinxAtStartPar
Manages data transfer back to research PACS systems

\item {} 
\sphinxAtStartPar
Provides project\sphinxhyphen{}specific data organization

\end{itemize}

\sphinxstepscope


\section{Data Flow}
\label{\detokenize{Architecture/data-flow:data-flow}}\label{\detokenize{Architecture/data-flow::doc}}
\sphinxAtStartPar
This document describes the complete data flow through the FIONA system, from initial DICOM reception to final transfer to research PACS.

\sphinxAtStartPar
Data flow overwie (ver.1 \sphinxhyphen{} detailed)

\sphinxincludegraphics{mermaid-722b1dae465b492ddef97f6013e994db1b183981.pdf}

\sphinxAtStartPar
Data flow diagram (ver.2 \sphinxhyphen{} more general)

\sphinxincludegraphics{mermaid-80e988bae676d1a7604f1ffbe4815ec3a76aa6a0.pdf}


\subsection{Data Flow Overview}
\label{\detokenize{Architecture/data-flow:data-flow-overview}}
\sphinxincludegraphics{mermaid-2afc7d3b1b37424684ac980e5225219ad8932be0.pdf}

\sphinxAtStartPar
The FIONA system processes medical image data through several distinct phases:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Data Reception} \sphinxhyphen{} DICOM files arrive from clinical systems

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Initial Processing} \sphinxhyphen{} Files are processed and classified

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Study Organization} \sphinxhyphen{} Data is organized into study/series structure

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Anonymization} \sphinxhyphen{} Data is anonymized for research use

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Transfer Preparation} \sphinxhyphen{} Data is prepared for transfer

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Export} \sphinxhyphen{} Data is transferred to research PACS

\end{enumerate}


\subsection{Detailed Data Flow}
\label{\detokenize{Architecture/data-flow:detailed-data-flow}}

\subsubsection{Phase 1: Data Reception}
\label{\detokenize{Architecture/data-flow:phase-1-data-reception}}
\sphinxAtStartPar
\sphinxstylestrong{Input:} DICOM files from clinical PACS
\sphinxstylestrong{Components:} storescpFIONA, storectl.sh
\sphinxstylestrong{Output:} Raw DICOM files in temporary storage

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Clinical PACS \(\rightarrow\) storescpFIONA \(\rightarrow\) /data/site/.arrived/
                                ↓
                          Named Pipe (/tmp/.processSingleFilePipe)
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Process:}
1. Clinical PACS sends DICOM files via DICOM protocol
2. storescpFIONA receives files and stores in \sphinxtitleref{/data/site/.arrived/}
3. File arrival notification sent via named pipe
4. Files moved to \sphinxtitleref{/data/site/archive/} for processing


\subsubsection{Phase 2: Initial Processing}
\label{\detokenize{Architecture/data-flow:phase-2-initial-processing}}
\sphinxAtStartPar
\sphinxstylestrong{Input:} Raw DICOM files
\sphinxstylestrong{Components:} processSingleFile3.py, receiveSingleFile.sh
\sphinxstylestrong{Output:} Processed DICOM files with metadata

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/data/site/archive/ \(\rightarrow\) processSingleFile3.py \(\rightarrow\) /data/site/raw/
                       ↓
                Classification Rules (classifyRules.json)
                       ↓
                Study/Series Organization
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Process:}
1. processSingleFile3.py daemon receives file notifications
2. DICOM headers are parsed and metadata extracted
3. Files are classified using rule\sphinxhyphen{}based system
4. Study and series information is organized
5. Symbolic links are created for easy access


\subsubsection{Phase 3: Study Organization}
\label{\detokenize{Architecture/data-flow:phase-3-study-organization}}
\sphinxAtStartPar
\sphinxstylestrong{Input:} Processed DICOM files
\sphinxstylestrong{Components:} detectStudyArrival.sh
\sphinxstylestrong{Output:} Organized study structure

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/data/site/raw/ \(\rightarrow\) detectStudyArrival.sh \(\rightarrow\) Study Job Directory
                   ↓
            Study Completion Detection
                   ↓
            Workflow Trigger
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Process:}
1. detectStudyArrival.sh monitors for completed studies
2. Study completion is detected when all series arrive
3. Study job directory is created
4. Workflow processes are triggered


\subsubsection{Phase 4: Anonymization}
\label{\detokenize{Architecture/data-flow:phase-4-anonymization}}
\sphinxAtStartPar
\sphinxstylestrong{Input:} Organized study data
\sphinxstylestrong{Components:} anonymizeAndSend.py, anonymize.sh
\sphinxstylestrong{Output:} Anonymized DICOM files

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Study Data \(\rightarrow\) anonymizeAndSend.py \(\rightarrow\) Anonymized Data
               ↓
        REDCap Configuration
               ↓
        Project\PYGZhy{}specific Rules
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Process:}
1. Transfer requests are read from REDCap
2. Project\sphinxhyphen{}specific anonymization rules are applied
3. DICOM tags are modified according to requirements
4. Anonymized files are prepared for transfer


\subsubsection{Phase 5: Transfer Preparation}
\label{\detokenize{Architecture/data-flow:phase-5-transfer-preparation}}
\sphinxAtStartPar
\sphinxstylestrong{Input:} Anonymized study data
\sphinxstylestrong{Components:} createTransferRequest.py, createZipFileCmd.php
\sphinxstylestrong{Output:} Transfer\sphinxhyphen{}ready data packages

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Anonymized Data \(\rightarrow\) createTransferRequest.py \(\rightarrow\) Transfer Package
                     ↓
              ZIP File Creation
                     ↓
              MD5 Checksum Generation
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Process:}
1. Transfer requests are processed
2. Data is packaged into ZIP files
3. MD5 checksums are generated for integrity
4. Transfer packages are prepared


\subsubsection{Phase 6: Export}
\label{\detokenize{Architecture/data-flow:phase-6-export}}
\sphinxAtStartPar
\sphinxstylestrong{Input:} Transfer packages
\sphinxstylestrong{Components:} sendFiles.sh
\sphinxstylestrong{Output:} Data transferred to research PACS

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Transfer Package \(\rightarrow\) sendFiles.sh \(\rightarrow\) Research PACS
                      ↓
               SFTP Transfer
                      ↓
               Transfer Confirmation
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{Process:}
1. SFTP connection established to research PACS
2. Files are transferred with integrity checking
3. Transfer status is logged
4. Success/failure notifications are sent


\subsection{Data Storage Structure}
\label{\detokenize{Architecture/data-flow:data-storage-structure}}
\sphinxAtStartPar
The FIONA system uses a hierarchical storage structure:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/data/
├── site/
│   ├── .arrived/          \PYGZsh{} Initial file reception
│   ├── archive/           \PYGZsh{} Raw DICOM storage
│   ├── raw/              \PYGZsh{} Processed DICOM files
│   └── output/           \PYGZsh{} Processing results
├── config/               \PYGZsh{} Configuration files
└── logs/                 \PYGZsh{} System logs
\end{sphinxVerbatim}

\sphinxAtStartPar
Project\sphinxhyphen{}specific directories follow the pattern:
/data\{PROJECT\}/site/…


\subsection{Communication Mechanisms}
\label{\detokenize{Architecture/data-flow:communication-mechanisms}}
\sphinxAtStartPar
\sphinxstylestrong{Named Pipes:}
\sphinxhyphen{} \sphinxtitleref{/tmp/.processSingleFilePipe} \sphinxhyphen{} File processing notifications
\sphinxhyphen{} Project\sphinxhyphen{}specific pipes: \sphinxtitleref{/tmp/.processSingleFilePipe\{PROJECT\}}

\sphinxAtStartPar
\sphinxstylestrong{Configuration Files:}
\sphinxhyphen{} \sphinxtitleref{/data/config/config.json} \sphinxhyphen{} Main system configuration
\sphinxhyphen{} \sphinxtitleref{classifyRules.json} \sphinxhyphen{} Classification rules
\sphinxhyphen{} REDCap integration for transfer management

\sphinxAtStartPar
\sphinxstylestrong{Log Files:}
\sphinxhyphen{} System logs in \sphinxtitleref{/var/www/html/server/logs/}
\sphinxhyphen{} Processing logs in \sphinxtitleref{/data/logs/}


\subsection{Error Handling and Recovery}
\label{\detokenize{Architecture/data-flow:error-handling-and-recovery}}
\sphinxAtStartPar
\sphinxstylestrong{File Processing Errors:}
\sphinxhyphen{} Failed files are logged and can be reprocessed
\sphinxhyphen{} Corrupted DICOM files are quarantined
\sphinxhyphen{} Processing retries are implemented

\sphinxAtStartPar
\sphinxstylestrong{Transfer Errors:}
\sphinxhyphen{} Failed transfers are retried automatically
\sphinxhyphen{} MD5 checksum verification ensures data integrity
\sphinxhyphen{} Transfer status is tracked in REDCap

\sphinxAtStartPar
\sphinxstylestrong{System Recovery:}
\sphinxhyphen{} Daemon processes can be restarted automatically
\sphinxhyphen{} File system consistency is maintained
\sphinxhyphen{} Backup and recovery procedures are in place


\subsection{Monitoring and Logging}
\label{\detokenize{Architecture/data-flow:monitoring-and-logging}}
\sphinxAtStartPar
\sphinxstylestrong{System Monitoring:}
\sphinxhyphen{} heartbeat.sh \sphinxhyphen{} System health monitoring
\sphinxhyphen{} cron.sh \sphinxhyphen{} Scheduled task management
\sphinxhyphen{} Log rotation and management

\sphinxAtStartPar
\sphinxstylestrong{Data Flow Monitoring:}
\sphinxhyphen{} File arrival detection
\sphinxhyphen{} Processing status tracking
\sphinxhyphen{} Transfer completion monitoring

\sphinxAtStartPar
This data flow ensures reliable, automated processing of medical image data while maintaining data integrity and compliance with research requirements.

\sphinxstepscope


\section{System components}
\label{\detokenize{Architecture/scripts:system-components}}\label{\detokenize{Architecture/scripts::doc}}
\sphinxstepscope

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{storectl.sh}} script is a system service controller for managing DICOM storage operations. It starts/stops the storescpFIONA daemon which receives DICOM files over the network and processes them through a named pipe system.


\subsection{Input/Output File Dependencies}
\label{\detokenize{Architecture/scripts/storectl:input-output-file-dependencies}}\label{\detokenize{Architecture/scripts/storectl::doc}}
\sphinxincludegraphics{mermaid-9696956adf6bca772bbc36ef2904079c802579bc.pdf}



\sphinxAtStartPar
\sphinxstylestrong{File Descriptions:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{config.json}} \sphinxhyphen{} Main configuration file containing DATADIR, DICOMPORT, and project settings

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{enabled}} \sphinxhyphen{} Control file to enable/disable the service (first character: 0=disabled, 1=enabled)

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{storectl.sh}} \sphinxhyphen{} Main control script for managing the DICOM storage daemon

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{storescpd.pid}} \sphinxhyphen{} Process ID file for tracking the running daemon

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{storescpd.log}} \sphinxhyphen{} Log file recording daemon activities and errors

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{processSingleFilePipe}} \sphinxhyphen{} Named pipe for communicating file reception events to processing system

\end{itemize}


\subsection{Data Flow Dependencies}
\label{\detokenize{Architecture/scripts/storectl:data-flow-dependencies}}
\sphinxincludegraphics{mermaid-9183a45d0bb6df2840a80335e435a78c39dbd581.pdf}



\sphinxAtStartPar
\sphinxstylestrong{Data Flow Components:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{DICOMNetwork}} \sphinxhyphen{} External DICOM devices sending medical imaging data over network

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{storescpFIONA}} \sphinxhyphen{} DICOM storage daemon that receives and processes incoming DICOM files

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{receiveSingleFile.sh}} \sphinxhyphen{} Script executed for each received DICOM file to handle initial processing

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{processSingleFilePipe}} \sphinxhyphen{} Named pipe used for inter\sphinxhyphen{}process communication between components

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{processSingleFile.py}} \sphinxhyphen{} Python script that processes DICOM file metadata and organizes data

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{ArchiveDirectory}} \sphinxhyphen{} File system location where DICOM files are permanently stored

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Directories:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\$\{DATADIR\}/site/archive}} \sphinxhyphen{} DICOM file storage location

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\$\{DATADIR\}/site/.arrived}} \sphinxhyphen{} Temporary arrival directory

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\$\{SERVERDIR\}/.pids/}} \sphinxhyphen{} PID file storage

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\$\{SERVERDIR\}/logs/}} \sphinxhyphen{} Log file directory

\end{itemize}


\subsubsection{storectl.sh}
\label{\detokenize{Architecture/scripts/storectl:storectl-sh}}
\sphinxAtStartPar
filename: storescpd

\sphinxAtStartPar
purpose: start storescp server for processing user at boot time to receive data
|         Move files to project specific file system

\sphinxAtStartPar
This system service will fail if a control file /data/enabled exists and  its first character is a “0”.

\sphinxAtStartPar
(Hauke Bartsch)

\sphinxstepscope


\subsection{processSingleFile3.py}
\label{\detokenize{Architecture/scripts/processSingleFile3:processsinglefile3-py}}\label{\detokenize{Architecture/scripts/processSingleFile3::doc}}
\sphinxAtStartPar
Create a daemon process that listens to send messages and reads a DICOM file,
extracts the header information and creates a Study/Series symbolic link structure.
\begin{description}
\sphinxlineitem{The parser for the Siemens CSA header have been adapted from}
\sphinxAtStartPar
\sphinxurl{https://scion.duhs.duke.edu/svn/vespa/tags/0\_1\_0/libduke\_mr/util\_dicom\_siemens.py}

\end{description}

\sphinxstepscope


\subsection{anonymizeAndSend.py}
\label{\detokenize{Architecture/scripts/anonymizeAndSend:anonymizeandsend-py}}\label{\detokenize{Architecture/scripts/anonymizeAndSend::doc}}
\sphinxAtStartPar
There is no docstring.

\sphinxAtStartPar
2025.06.17 mk

\sphinxstepscope


\subsection{detectStudyArrival.sh}
\label{\detokenize{Architecture/scripts/detectStudyArrival:detectstudyarrival-sh}}\label{\detokenize{Architecture/scripts/detectStudyArrival::doc}}
\sphinxAtStartPar
check the study job directory created by receiveSingleFile.sh

\sphinxAtStartPar
if the file is old enough process it using the information provided

\sphinxAtStartPar
Add this to “crontab \sphinxhyphen{}e” to check every 15 seconds if a new job arrived.
\sphinxcode{\sphinxupquote{*/1 * * * * /data/code/bin/detectStudyArrival.sh}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 30; /data/code/bin/detectStudyArrival.sh}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 15; /data/code/bin/detectStudyArrival.sh}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 45; /data/code/bin/detectStudyArrival.sh}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * /data/code/bin/detectStudyArrival.sh PCGC}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 30; /data/code/bin/detectStudyArrival.sh PCGC}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 15; /data/code/bin/detectStudyArrival.sh PCGC}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{*/1 * * * * sleep 45; /data/code/bin/detectStudyArrival.sh PCGC}}

\sphinxstepscope


\subsection{sendFiles.sh}
\label{\detokenize{Architecture/scripts/sendFiles:sendfiles-sh}}\label{\detokenize{Architecture/scripts/sendFiles::doc}}
\sphinxAtStartPar
Example crontab entry that starts this script every 30 minutes

\begin{sphinxVerbatim}[commandchars=\\\{\}]
*/30 * * * * /usr/bin/nice \PYGZhy{}n 3 /var/www/html/server/bin/sendFiles.sh
\end{sphinxVerbatim}

\sphinxAtStartPar
Add the above line to your machine using:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZgt{}\PYG{+w}{ }crontab\PYG{+w}{ }\PYGZhy{}e
\end{sphinxVerbatim}

\sphinxAtStartPar
This script is supposed to send compressed data files for DICOM and k\sphinxhyphen{}space to the DAIC endpoint using sftp. All data in the /data/outbox directory will be send using local and DAIC md5sum files.

\sphinxstepscope


\subsection{mppsctl.sh}
\label{\detokenize{Architecture/scripts/mppsctl:mppsctl-sh}}\label{\detokenize{Architecture/scripts/mppsctl::doc}}
\sphinxAtStartPar
filename: ppsscpfs
\begin{description}
\sphinxlineitem{purpose:}\begin{itemize}
\item {} 
\sphinxAtStartPar
start DICOM multiple performed procedure steps server

\item {} 
\sphinxAtStartPar
Keeps track of scans on the server:

\end{itemize}

\end{description}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
*/1 * * * * /var/www/html/server/bin/mppsctl.sh start
\end{sphinxVerbatim}

\sphinxAtStartPar
(Hauke Bartsch)

\sphinxstepscope


\subsection{parseAllPatients.sh}
\label{\detokenize{Architecture/scripts/parseAllPatients:parseallpatients-sh}}\label{\detokenize{Architecture/scripts/parseAllPatients::doc}}
\sphinxAtStartPar
depends on output generated by getAllPatients2.sh

\sphinxAtStartPar
get list of optional findscu entries from \sphinxurl{http://dicom.nema.org/medical/dicom/current/output/html/part04.html\#sect\_C.6.1.1}

\sphinxstepscope


\subsection{process\_tiff.sh}
\label{\detokenize{Architecture/scripts/process_tiff:process-tiff-sh}}\label{\detokenize{Architecture/scripts/process_tiff::doc}}
\sphinxAtStartPar
To be updated.

\sphinxstepscope


\subsection{removeOldEntries.sh}
\label{\detokenize{Architecture/scripts/removeOldEntries:removeoldentries-sh}}\label{\detokenize{Architecture/scripts/removeOldEntries::doc}}
\sphinxAtStartPar
Rremove any old entries from incoming.txt

\sphinxstepscope


\subsection{runOneJob.sh}
\label{\detokenize{Architecture/scripts/runOneJob:runonejob-sh}}\label{\detokenize{Architecture/scripts/runOneJob::doc}}
\sphinxAtStartPar
Run a single job from the workflow\_joblist.jobs file. The file contains json code per line.

\sphinxAtStartPar
Need to run as user “processing” with flock.
\begin{description}
\sphinxlineitem{Example cron job:}\begin{description}
\sphinxlineitem{/usr/bin/flock \sphinxhyphen{}n /home/processing/.pids/Workflows\_RunOneJob.pid }
\sphinxAtStartPar
/var/www/html/applications/Workflows/php/runOneJob.sh \textgreater{}\textgreater{} /home/processing/logs/Workflows\_RunOneJob.log 2\textgreater{}\&1

\end{description}

\end{description}

\sphinxstepscope


\subsection{getAllPatients2.sh}
\label{\detokenize{Architecture/scripts/getAllPatients2:getallpatients2-sh}}\label{\detokenize{Architecture/scripts/getAllPatients2::doc}}
\sphinxAtStartPar
We can provide an argument to this program, the maximum number of days we would like to pull. In general we might get away with a very short
period because new scans will come in as recent scans. But some test data migth be very old. So we should do one long run at night and short
runs during the day.

\sphinxAtStartPar
As a second argument allow a specific project name. The whole things takes too long right now. Treat some project as special here.

\sphinxstepscope


\subsection{heartbeat.sh}
\label{\detokenize{Architecture/scripts/heartbeat:heartbeat-sh}}\label{\detokenize{Architecture/scripts/heartbeat::doc}}
\sphinxAtStartPar
create a heart beat for the storescp

\sphinxAtStartPar
One way it can fail is if multiple associations are requested.

\sphinxAtStartPar
If the timeout happens the connection will be unusable afterwards.

\sphinxAtStartPar
Here we simply use echoscu to test the connection and if that fails we will kill a running storescp (hoping that monit will start it again).

\sphinxAtStartPar
In order to activate put this into the crontab of processing (every minute):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
*/1 * * * * /usr/bin/nice \PYGZhy{}n 3 /var/www/html/server/bin/heartbeat.sh
\end{sphinxVerbatim}

\sphinxstepscope


\subsection{moveFromScanner.sh}
\label{\detokenize{Architecture/scripts/moveFromScanner:movefromscanner-sh}}\label{\detokenize{Architecture/scripts/moveFromScanner::doc}}
\sphinxAtStartPar
Called from cron\sphinxhyphen{}job, checks the study data in /dataPCGC/active\sphinxhyphen{}scans for things to pull from the scanner.

\sphinxAtStartPar
If all images are already found (only checks number of images) the series will not be pulled again.
If all images of all series are present on the system the /dataPCGC/active\sphinxhyphen{}scans/\textless{}StudyInstanceUID\textgreater{} file is copied to the /dataPCGC/finished\sphinxhyphen{}scans/ folder.

\sphinxAtStartPar
This script will only run if there is no “/var/www/html/server/.pids/moveFromScannerPCGC.lock”. This prevents multiple executions of this script in cases that a single processing steps takes more than 15 seconds.

\sphinxAtStartPar
This script will only run if there is no “0” in the second /dataPCGC/enabled bin (like in “101”).

\sphinxAtStartPar
This script depends on the following dcmtk tools: dcm2dump, findscu, movescu.

\sphinxAtStartPar
Install using a cron\sphinxhyphen{}job every 15 seconds

\begin{sphinxVerbatim}[commandchars=\\\{\}]
*/1 * * * * /var/www/html/server/bin/moveFromScanner.sh
*/1 * * * * sleep 30; /var/www/html/server/bin/moveFromScanner.sh
*/1 * * * * sleep 15; /var/www/html/server/bin/moveFromScanner.sh
*/1 * * * * sleep 45; /var/www/html/server/bin/moveFromScanner.sh
*/1 * * * * /var/www/html/server/bin/moveFromScanner.sh PCGC
*/1 * * * * sleep 30; /var/www/html/server/bin/moveFromScanner.sh PCGC
*/1 * * * * sleep 15; /var/www/html/server/bin/moveFromScanner.sh PCGC
*/1 * * * * sleep 45; /var/www/html/server/bin/moveFromScanner.sh PCGC
\end{sphinxVerbatim}

\sphinxstepscope


\subsection{clearExports.sh}
\label{\detokenize{Architecture/scripts/clearExports:clearexports-sh}}\label{\detokenize{Architecture/scripts/clearExports::doc}}
\sphinxAtStartPar
find . \sphinxhyphen{}type d \sphinxhyphen{}maxdepth 1 \sphinxhyphen{}printf ‘\%T+ “\%p”n’ | sort | less

\sphinxAtStartPar
delete oldest files until we have at least 20\% free space on this partition

\sphinxstepscope


\subsection{clearOldFiles.sh}
\label{\detokenize{Architecture/scripts/clearOldFiles:clearoldfiles-sh}}\label{\detokenize{Architecture/scripts/clearOldFiles::doc}}
\sphinxAtStartPar
find . \sphinxhyphen{}type d \sphinxhyphen{}maxdepth 1 \sphinxhyphen{}printf ‘\%T+ “\%p”n’ | sort | less

\sphinxAtStartPar
delete oldest files until we have at least 20\% free space on this partition

\sphinxAtStartPar
TODO: delete links in /data/site/participants/

\sphinxAtStartPar
TODO: delete links in /data/site/srs/

\sphinxstepscope


\subsection{clearStaleLinks.sh}
\label{\detokenize{Architecture/scripts/clearStaleLinks:clearstalelinks-sh}}\label{\detokenize{Architecture/scripts/clearStaleLinks::doc}}
\sphinxAtStartPar
Delete links that do not point to real images in archive.

\sphinxAtStartPar
Just to be sure we have a clear /data/site/raw folder we should remove broken symbolic link and empty folders.

\sphinxstepscope


\subsection{cron.sh}
\label{\detokenize{Architecture/scripts/cron:cron-sh}}\label{\detokenize{Architecture/scripts/cron::doc}}
\sphinxAtStartPar
There is no docstring.

\sphinxstepscope


\subsection{whatIsInIDS7.py}
\label{\detokenize{Architecture/scripts/whatIsInIDS7:whatisinids7-py}}\label{\detokenize{Architecture/scripts/whatIsInIDS7::doc}}
\sphinxAtStartPar
TODO: check if the number of study related series is correct (looks too large in Export app)

\sphinxstepscope


\subsection{whatIsNotInIDS7.py}
\label{\detokenize{Architecture/scripts/whatIsNotInIDS7:whatisnotinids7-py}}\label{\detokenize{Architecture/scripts/whatIsNotInIDS7::doc}}
\sphinxAtStartPar
There is no docstring.

\sphinxstepscope


\subsection{createTransferRequestProcessed.py}
\label{\detokenize{Architecture/scripts/createTransferRequestForProcessed:createtransferrequestprocessed-py}}\label{\detokenize{Architecture/scripts/createTransferRequestForProcessed::doc}}
\sphinxAtStartPar
There is no docstring.

\sphinxstepscope


\subsection{populateAutoID.py}
\label{\detokenize{Architecture/scripts/populateAutoID:populateautoid-py}}\label{\detokenize{Architecture/scripts/populateAutoID::doc}}
\sphinxAtStartPar
Check all auto\sphinxhyphen{}id projects and create new transfer requests for each

\sphinxstepscope


\subsection{populateIncoming.py}
\label{\detokenize{Architecture/scripts/populateIncoming:populateincoming-py}}\label{\detokenize{Architecture/scripts/populateIncoming::doc}}
\sphinxAtStartPar
This program fills in the Study and Series information in the Incoming table in REDCap.

\sphinxAtStartPar
If a CouplingList entry exists its also adding a TransferRequest so that anonymizeAndSend can do its job.

\sphinxAtStartPar
TODO: support a new CouplingList entry even if there is already a TransferRequest done.

\sphinxstepscope


\subsection{populateProjects.py}
\label{\detokenize{Architecture/scripts/populateProjects:populateprojects-py}}\label{\detokenize{Architecture/scripts/populateProjects::doc}}
\sphinxAtStartPar
Each study that has been forwarded to PACS should appear in its own REDCap project.

\sphinxAtStartPar
We can get a list of all transferred studies from incomings transfers. We get a token for the project and add the entry \sphinxhyphen{} if it does not exist yet.

\sphinxAtStartPar
For informatino to appear in the Imaging instrument you need to set it up as a repeating instrument for “Event 1” (not a repeating event!).

\sphinxAtStartPar
TODO: Without calling for specific projects does not work anymore. We need to get a list of all imaging projects and run them project by project.

\sphinxstepscope


\subsection{resendProject.py}
\label{\detokenize{Architecture/scripts/resendProject:resendproject-py}}\label{\detokenize{Architecture/scripts/resendProject::doc}}
\sphinxAtStartPar
check all transfer requests that have already been done

\sphinxAtStartPar
if the send date is before the request date send again

\sphinxstepscope


\subsection{createTransferRequest.py}
\label{\detokenize{Architecture/scripts/createTransferRequest:createtransferrequest-py}}\label{\detokenize{Architecture/scripts/createTransferRequest::doc}}
\sphinxAtStartPar
There is no docstring.

\sphinxstepscope


\subsection{createZipFileCmd.php}
\label{\detokenize{Architecture/scripts/createZipFileCmd:createzipfilecmd-php}}\label{\detokenize{Architecture/scripts/createZipFileCmd::doc}}
\sphinxAtStartPar
This is a docstring.

\sphinxstepscope


\chapter{End User / Admin / Architecture (???)}
\label{\detokenize{Temp/index:end-user-admin-architecture}}\label{\detokenize{Temp/index::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} us: mk \& hb

\sphinxstepscope


\section{\sphinxstylestrong{* END USER (options) *}}
\label{\detokenize{Temp/end-user-options:end-user-options}}\label{\detokenize{Temp/end-user-options::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} Doctors, researchers, medical personnel

\sphinxAtStartPar
\sphinxstylestrong{Should contain:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
How to use the FIONA interface

\item {} 
\sphinxAtStartPar
How to browse medical images

\item {} 
\sphinxAtStartPar
How to export data

\item {} 
\sphinxAtStartPar
Step\sphinxhyphen{}by\sphinxhyphen{}step instructions

\item {} 
\sphinxAtStartPar
Interface screenshots

\item {} 
\sphinxAtStartPar
FAQ for users

\end{itemize}


\bigskip\hrule\bigskip



\section{System Overview}
\label{\detokenize{Temp/end-user-options:system-overview}}
\sphinxAtStartPar
The Fiona system is a comprehensive solution for managing DICOM medical images in a research environment. The system enables automatic reception, processing, anonymization, and transfer of imaging data between different PACS (Picture Archiving and Communication System) systems.


\section{Core Functions for End Users}
\label{\detokenize{Temp/end-user-options:core-functions-for-end-users}}

\subsection{1.1 DICOM Image Reception and Processing}
\label{\detokenize{Temp/end-user-options:dicom-image-reception-and-processing}}
\sphinxAtStartPar
\sphinxstylestrong{Automatic Reception}: The system automatically receives DICOM images from various scanners and workstations

\sphinxAtStartPar
\sphinxstylestrong{Series Classification}: Images are automatically classified according to defined rules

\sphinxAtStartPar
\sphinxstylestrong{Multi\sphinxhyphen{}Modality Support}: MR, CT, US, SR (Structured Reports), PR (Presentation States)


\subsection{1.2 Research Project Management}
\label{\detokenize{Temp/end-user-options:research-project-management}}
\sphinxAtStartPar
\sphinxstylestrong{Multi\sphinxhyphen{}Project Environment}: The system supports multiple independent research projects

\sphinxAtStartPar
\sphinxstylestrong{Data Routing}: Automatic routing of data to appropriate projects based on rules

\sphinxAtStartPar
\sphinxstylestrong{Auto\sphinxhyphen{}ID}: Automatic generation of participant identifiers for projects


\subsection{1.3 Export and Archiving}
\label{\detokenize{Temp/end-user-options:export-and-archiving}}\begin{description}
\sphinxlineitem{\sphinxstylestrong{Multiple Export Formats}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Native DICOM

\item {} 
\sphinxAtStartPar
NIFTI (for neuroimaging)

\item {} 
\sphinxAtStartPar
PURE (directory structure by series description)

\item {} 
\sphinxAtStartPar
Spectroscopy (spectroscopic data only)

\end{itemize}

\end{description}

\sphinxAtStartPar
\sphinxstylestrong{Anonymization}: Automatic removal of patient identifying data

\sphinxAtStartPar
\sphinxstylestrong{Secure Downloads}: Ability to create password\sphinxhyphen{}encrypted archives


\subsection{1.4 REDCap Integration}
\label{\detokenize{Temp/end-user-options:redcap-integration}}
\sphinxAtStartPar
\sphinxstylestrong{Data Synchronization}: Automatic synchronization with REDCap databases

\sphinxAtStartPar
\sphinxstylestrong{Transfer Requests}: Management of data transfer requests

\sphinxAtStartPar
\sphinxstylestrong{Metadata}: Storage and management of project metadata


\section{Supported File Types}
\label{\detokenize{Temp/end-user-options:supported-file-types}}

\subsection{DICOM Images}
\label{\detokenize{Temp/end-user-options:dicom-images}}\begin{itemize}
\item {} 
\sphinxAtStartPar
All standard DICOM modalities

\item {} 
\sphinxAtStartPar
Multi\sphinxhyphen{}frame and enhanced DICOM objects

\item {} 
\sphinxAtStartPar
Structured reports and presentation states

\end{itemize}


\subsection{Export Formats}
\label{\detokenize{Temp/end-user-options:export-formats}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{DICOM}: Original format with anonymization

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{NIFTI}: Neuroimaging format with JSON sidecars

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{PURE}: Organized directory structure

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{RAM\sphinxhyphen{}MS}: Specialized format for multiple sclerosis studies

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Transpara}: Format for prostate imaging studies

\end{itemize}


\section{User Interface Components}
\label{\detokenize{Temp/end-user-options:user-interface-components}}

\subsection{Exports Application}
\label{\detokenize{Temp/end-user-options:exports-application}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Search and filter studies by project, participant, date

\item {} 
\sphinxAtStartPar
Select export format and anonymization level

\item {} 
\sphinxAtStartPar
Download encrypted archives

\item {} 
\sphinxAtStartPar
Track export status and history

\end{itemize}


\subsection{Assign Application}
\label{\detokenize{Temp/end-user-options:assign-application}}\begin{itemize}
\item {} 
\sphinxAtStartPar
View incoming studies awaiting assignment

\item {} 
\sphinxAtStartPar
Manual assignment to research projects

\item {} 
\sphinxAtStartPar
Coupling list management

\item {} 
\sphinxAtStartPar
Study metadata review

\end{itemize}


\subsection{Attach Application}
\label{\detokenize{Temp/end-user-options:attach-application}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Upload whole slide imaging files

\item {} 
\sphinxAtStartPar
Automatic conversion to DICOM format

\item {} 
\sphinxAtStartPar
Metadata extraction and validation

\item {} 
\sphinxAtStartPar
Integration with pathology databases

\end{itemize}


\subsection{Workflows Application}
\label{\detokenize{Temp/end-user-options:workflows-application}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Launch containerized analysis workflows

\item {} 
\sphinxAtStartPar
Monitor processing status

\item {} 
\sphinxAtStartPar
Access results and outputs

\item {} 
\sphinxAtStartPar
Integration with research pipelines

\end{itemize}


\subsection{Support Contacts}
\label{\detokenize{Temp/end-user-options:support-contacts}}\begin{quote}

\sphinxAtStartPar
Emails
\end{quote}

\sphinxstepscope


\section{\sphinxstylestrong{* ADMIN (options) *}}
\label{\detokenize{Temp/admin-options:admin-options}}\label{\detokenize{Temp/admin-options::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} IT administrators, DevOps

\sphinxAtStartPar
\sphinxstylestrong{Should contain:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
FIONA installation instructions

\item {} 
\sphinxAtStartPar
Server configuration

\item {} 
\sphinxAtStartPar
User management

\item {} 
\sphinxAtStartPar
Monitoring and logs

\item {} 
\sphinxAtStartPar
Backup and recovery

\item {} 
\sphinxAtStartPar
Troubleshooting

\item {} 
\sphinxAtStartPar
System requirements

\end{itemize}


\bigskip\hrule\bigskip



\section{System Architecture}
\label{\detokenize{Temp/admin-options:system-architecture}}
\sphinxAtStartPar
The Fiona system consists of the following main components:


\subsection{2.1 DICOM Servers}
\label{\detokenize{Temp/admin-options:dicom-servers}}
\sphinxAtStartPar
\sphinxstylestrong{storescp}: Server receiving DICOM data

\sphinxAtStartPar
\sphinxstylestrong{findscu/movescu}: Clients for searching and retrieving data from PACS

\sphinxAtStartPar
\sphinxstylestrong{echoscu}: Connection monitoring


\subsection{2.2 Processing Components}
\label{\detokenize{Temp/admin-options:processing-components}}
\sphinxAtStartPar
\sphinxstylestrong{processSingleFile}: Daemon processing individual DICOM files

\sphinxAtStartPar
\sphinxstylestrong{detectStudyArrival}: Detection of completed image series reception

\sphinxAtStartPar
\sphinxstylestrong{anonymizeAndSend}: Data anonymization and transmission


\subsection{2.3 Project Management}
\label{\detokenize{Temp/admin-options:project-management}}
\sphinxAtStartPar
\sphinxstylestrong{populateIncoming}: Analysis of incoming data

\sphinxAtStartPar
\sphinxstylestrong{populateProjects}: REDCap project updates

\sphinxAtStartPar
\sphinxstylestrong{populateAutoID}: Automatic identifier generation


\section{Installation and Configuration}
\label{\detokenize{Temp/admin-options:installation-and-configuration}}

\subsection{2.1 System Requirements}
\label{\detokenize{Temp/admin-options:system-requirements}}
\sphinxAtStartPar
\sphinxstylestrong{OS}: Linux (Ubuntu/Debian preferred)

\sphinxAtStartPar
\sphinxstylestrong{Python}: 3.x with libraries: pydicom, pycurl, json

\sphinxAtStartPar
\sphinxstylestrong{DCMTK}: DICOM tools

\sphinxAtStartPar
\sphinxstylestrong{Docker}: For containerized processes

\sphinxAtStartPar
\sphinxstylestrong{REDCap}: Research data management system


\subsection{2.2 Directory Structure}
\label{\detokenize{Temp/admin-options:directory-structure}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/data/
├── config/
│   ├── config.json          \PYGZsh{} Main configuration
│   └── enabled              \PYGZsh{} Enable/disable flag
├── site/
│   ├── archive/             \PYGZsh{} DICOM archive (scp\PYGZus{}\PYGZlt{}StudyInstanceUID\PYGZgt{})
│   ├── raw/                 \PYGZsh{} Raw data (StudyInstanceUID/SeriesInstanceUID)
│   ├── participants/        \PYGZsh{} Per\PYGZhy{}patient links
│   ├── srs/                 \PYGZsh{} Structured Reports
│   └── .arrived/            \PYGZsh{} Arrival information for series
└── outbox/                  \PYGZsh{} Data for external transmission
\end{sphinxVerbatim}


\subsection{2.3 Configuration (config.json)}
\label{\detokenize{Temp/admin-options:configuration-config-json}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{p}{\PYGZob{}}
\PYG{+w}{  }\PYG{n+nt}{\PYGZdq{}DATADIR\PYGZdq{}}\PYG{p}{:}\PYG{+w}{ }\PYG{l+s+s2}{\PYGZdq{}/data\PYGZdq{}}\PYG{p}{,}
\PYG{+w}{  }\PYG{n+nt}{\PYGZdq{}DICOMPORT\PYGZdq{}}\PYG{p}{:}\PYG{+w}{ }\PYG{l+s+s2}{\PYGZdq{}7840\PYGZdq{}}\PYG{p}{,}
\PYG{+w}{  }\PYG{n+nt}{\PYGZdq{}DICOMIP\PYGZdq{}}\PYG{p}{:}\PYG{+w}{ }\PYG{l+s+s2}{\PYGZdq{}127.0.0.1\PYGZdq{}}\PYG{p}{,}
\PYG{+w}{  }\PYG{n+nt}{\PYGZdq{}DICOMAETITLE\PYGZdq{}}\PYG{p}{:}\PYG{+w}{ }\PYG{l+s+s2}{\PYGZdq{}FIONA\PYGZdq{}}\PYG{p}{,}
\PYG{+w}{  }\PYG{n+nt}{\PYGZdq{}PROCESSING\PYGZus{}USER\PYGZdq{}}\PYG{p}{:}\PYG{+w}{ }\PYG{l+s+s2}{\PYGZdq{}processing\PYGZdq{}}\PYG{p}{,}
\PYG{+w}{  }\PYG{n+nt}{\PYGZdq{}SITES\PYGZdq{}}\PYG{p}{:}\PYG{+w}{ }\PYG{p}{\PYGZob{}}
\PYG{+w}{    }\PYG{n+nt}{\PYGZdq{}PROJECT\PYGZus{}NAME\PYGZdq{}}\PYG{p}{:}\PYG{+w}{ }\PYG{p}{\PYGZob{}}
\PYG{+w}{      }\PYG{n+nt}{\PYGZdq{}DATADIR\PYGZdq{}}\PYG{p}{:}\PYG{+w}{ }\PYG{l+s+s2}{\PYGZdq{}/dataPROJECT\PYGZdq{}}\PYG{p}{,}
\PYG{+w}{      }\PYG{n+nt}{\PYGZdq{}DICOMPORT\PYGZdq{}}\PYG{p}{:}\PYG{+w}{ }\PYG{l+s+s2}{\PYGZdq{}7841\PYGZdq{}}
\PYG{+w}{    }\PYG{p}{\PYGZcb{}}
\PYG{+w}{  }\PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\section{Processes and Services}
\label{\detokenize{Temp/admin-options:processes-and-services}}

\subsection{2.4 Main Daemons}
\label{\detokenize{Temp/admin-options:main-daemons}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{storescp} (storectl.sh):
\sphinxhyphen{} DICOM listening port
\sphinxhyphen{} File reception and storage
\sphinxhyphen{} processSingleFile invocation

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{processSingleFile} (processSingleFile3.py):
\sphinxhyphen{} DICOM metadata processing
\sphinxhyphen{} Image series classification
\sphinxhyphen{} Directory structure creation

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{detectStudyArrival} (detectStudyArrival.sh):
\sphinxhyphen{} Series transfer completion detection
\sphinxhyphen{} Post\sphinxhyphen{}processing initiation
\sphinxhyphen{} Data archiving

\end{enumerate}


\subsection{2.5 Cron Jobs}
\label{\detokenize{Temp/admin-options:cron-jobs}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Basic processes (every minute)}
*/1\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }/var/www/html/server/bin/storectl.sh\PYG{+w}{ }start
*/1\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }/var/www/html/server/bin/heartbeat.sh
*/1\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }/var/www/html/server/bin/detectStudyArrival.sh

\PYG{c+c1}{\PYGZsh{} Data processing (every 5 minutes)}
*/5\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }/usr/bin/python3\PYG{+w}{ }/var/www/html/server/bin/populateIncoming.py
*/5\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }/usr/bin/python3\PYG{+w}{ }/var/www/html/server/bin/createTransferRequest.py
*/5\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }/usr/bin/python3\PYG{+w}{ }/var/www/html/server/bin/anonymizeAndSend.py

\PYG{c+c1}{\PYGZsh{} Export (every 30 minutes)}
*/30\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }/var/www/html/server/bin/sendFiles.sh

\PYG{c+c1}{\PYGZsh{} Cleanup (daily)}
\PYG{l+m}{0}\PYG{+w}{ }\PYG{l+m}{2}\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }/var/www/html/server/bin/clearOldFiles.sh
\PYG{l+m}{0}\PYG{+w}{ }\PYG{l+m}{3}\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }*\PYG{+w}{ }/var/www/html/server/bin/clearStaleLinks.sh
\end{sphinxVerbatim}


\section{Monitoring and Troubleshooting}
\label{\detokenize{Temp/admin-options:monitoring-and-troubleshooting}}

\subsection{2.6 System Logs}
\label{\detokenize{Temp/admin-options:system-logs}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{/var/www/html/server/logs/}} \sphinxhyphen{} main system logs

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{/home/processing/logs/}} \sphinxhyphen{} processing user logs

\item {} 
\sphinxAtStartPar
Monitoring through syslog

\end{itemize}


\subsection{2.7 Common Problems}
\label{\detokenize{Temp/admin-options:common-problems}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Disk Space Issues}: clearOldFiles.sh, clearExports.sh

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Blocked Processes}: heartbeat.sh restarts services

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{REDCap Problems}: Check tokens in tokens.json

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{DICOM Connectivity}: echoscu for connection testing

\end{enumerate}


\section{Security}
\label{\detokenize{Temp/admin-options:security}}

\subsection{2.8 Data Anonymization}
\label{\detokenize{Temp/admin-options:data-anonymization}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Patient identifier removal

\item {} 
\sphinxAtStartPar
Date modification (42\sphinxhyphen{}day shift for RAM\sphinxhyphen{}MS)

\item {} 
\sphinxAtStartPar
DICOM tag export control

\end{itemize}


\subsection{2.9 Access Control}
\label{\detokenize{Temp/admin-options:access-control}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{processing}} user for system processes

\item {} 
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{www\sphinxhyphen{}data}} group for web interface

\item {} 
\sphinxAtStartPar
777 permissions for shared directories

\end{itemize}


\section{Backup and Recovery}
\label{\detokenize{Temp/admin-options:backup-and-recovery}}

\subsection{Backup Strategy}
\label{\detokenize{Temp/admin-options:backup-strategy}}\begin{description}
\sphinxlineitem{\sphinxstylestrong{Critical Data}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Archive directory (\sphinxcode{\sphinxupquote{/data/site/archive/}})

\item {} 
\sphinxAtStartPar
Configuration files (\sphinxcode{\sphinxupquote{config.json}}, \sphinxcode{\sphinxupquote{tokens.json}})

\item {} 
\sphinxAtStartPar
REDCap databases

\item {} 
\sphinxAtStartPar
Log files for audit trail

\end{itemize}

\sphinxlineitem{\sphinxstylestrong{Backup Schedule}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Daily: Configuration and logs

\item {} 
\sphinxAtStartPar
Weekly: Full archive backup

\item {} 
\sphinxAtStartPar
Monthly: Complete system backup

\end{itemize}

\end{description}


\subsection{Recovery Procedures}
\label{\detokenize{Temp/admin-options:recovery-procedures}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Service Recovery}: Use heartbeat.sh and systemctl

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Data Recovery}: Restore from archive backups

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Configuration Recovery}: Restore config files and restart services

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Database Recovery}: REDCap backup restoration

\end{enumerate}


\section{Performance Tuning}
\label{\detokenize{Temp/admin-options:performance-tuning}}

\subsection{Optimization Settings}
\label{\detokenize{Temp/admin-options:optimization-settings}}\begin{description}
\sphinxlineitem{\sphinxstylestrong{Parallel Processing}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Multiple processSingleFile instances

\item {} 
\sphinxAtStartPar
Chunked REDCap API calls

\item {} 
\sphinxAtStartPar
Background export processing

\end{itemize}

\sphinxlineitem{\sphinxstylestrong{Storage Optimization}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Symbolic links instead of file copies

\item {} 
\sphinxAtStartPar
Automatic cleanup of old data

\item {} 
\sphinxAtStartPar
Compressed archives for export

\end{itemize}

\sphinxlineitem{\sphinxstylestrong{Network Optimization}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Connection pooling for DICOM operations

\item {} 
\sphinxAtStartPar
Bandwidth limiting for external transfers

\item {} 
\sphinxAtStartPar
Timeout management for long operations

\end{itemize}

\end{description}


\section{Maintenance Procedures}
\label{\detokenize{Temp/admin-options:maintenance-procedures}}

\subsection{Daily Tasks}
\label{\detokenize{Temp/admin-options:daily-tasks}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Monitor disk space usage

\item {} 
\sphinxAtStartPar
Check service status

\item {} 
\sphinxAtStartPar
Review error logs

\item {} 
\sphinxAtStartPar
Verify REDCap connectivity

\end{itemize}


\subsection{Weekly Tasks}
\label{\detokenize{Temp/admin-options:weekly-tasks}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Clean up old export files

\item {} 
\sphinxAtStartPar
Update routing rules if needed

\item {} 
\sphinxAtStartPar
Backup configuration files

\item {} 
\sphinxAtStartPar
Performance monitoring

\end{itemize}


\subsection{Monthly Tasks}
\label{\detokenize{Temp/admin-options:monthly-tasks}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Full system backup

\item {} 
\sphinxAtStartPar
Update documentation

\item {} 
\sphinxAtStartPar
Review user access permissions

\item {} 
\sphinxAtStartPar
System security audit

\end{itemize}

\sphinxstepscope


\section{\sphinxstylestrong{* ARCHITECTURE (options) *}}
\label{\detokenize{Temp/architecture-options:architecture-options}}\label{\detokenize{Temp/architecture-options::doc}}
\sphinxAtStartPar
\sphinxstylestrong{For:} Developers, system architects

\sphinxAtStartPar
\sphinxstylestrong{Contains:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Source code documentation

\item {} 
\sphinxAtStartPar
System components description

\item {} 
\sphinxAtStartPar
APIs and interfaces

\item {} 
\sphinxAtStartPar
Scripts and tools

\item {} 
\sphinxAtStartPar
Data flow diagrams

\end{itemize}


\subsection{Core Components}
\label{\detokenize{Temp/architecture-options:core-components}}

\subsubsection{Data Reception}
\label{\detokenize{Temp/architecture-options:data-reception}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{storescpFIONA} \sphinxhyphen{} Custom DICOM SCP (Service Class Provider) server

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{storectl.sh} \sphinxhyphen{} Service controller for DICOM reception

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Named pipes} \sphinxhyphen{} Communication mechanism between components

\end{itemize}


\subsubsection{Data Processing}
\label{\detokenize{Temp/architecture-options:data-processing}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{processSingleFile3.py} \sphinxhyphen{} Main DICOM processing daemon

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{detectStudyArrival.sh} \sphinxhyphen{} Study arrival detection and workflow management

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Classification system} \sphinxhyphen{} Rule\sphinxhyphen{}based study classification

\end{itemize}


\subsubsection{Data Management}
\label{\detokenize{Temp/architecture-options:data-management}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{File system organization} \sphinxhyphen{} Project\sphinxhyphen{}specific directory structures

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Symbolic link management} \sphinxhyphen{} Study/Series organization

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Data cleanup} \sphinxhyphen{} Automated file maintenance

\end{itemize}


\subsubsection{Data Transfer}
\label{\detokenize{Temp/architecture-options:data-transfer}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{anonymizeAndSend.py} \sphinxhyphen{} Data anonymization and transfer

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{sendFiles.sh} \sphinxhyphen{} Automated file transfer to research PACS

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Transfer request system} \sphinxhyphen{} REDCap integration for transfer management

\end{itemize}


\subsection{System Architecture}
\label{\detokenize{Temp/architecture-options:system-architecture}}
\sphinxAtStartPar
FIONA operates as a multi\sphinxhyphen{}layered system:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Network Layer} \sphinxhyphen{} DICOM protocol handling

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Processing Layer} \sphinxhyphen{} Data classification and organization

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Storage Layer} \sphinxhyphen{} File system management

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Transfer Layer} \sphinxhyphen{} Data export and anonymization

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Management Layer} \sphinxhyphen{} Monitoring and control

\end{enumerate}

\sphinxAtStartPar
General overwier (ver. 1)

\sphinxincludegraphics{mermaid-78717e965f054802cff20e181650cb0d915406b5.pdf}


\bigskip\hrule\bigskip


\sphinxAtStartPar
More detailed system overwier (ver. 2).

\sphinxincludegraphics{mermaid-63e15246208d0af88ea42454acfdfa50ccbfe73a.pdf}


\subsection{Key Features}
\label{\detokenize{Temp/architecture-options:key-features}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Multi\sphinxhyphen{}project support} \sphinxhyphen{} Handles multiple research projects simultaneously

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Automated workflows} \sphinxhyphen{} Minimal human intervention required

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Data anonymization} \sphinxhyphen{} Compliant with research privacy requirements

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Scalable design} \sphinxhyphen{} Can handle high\sphinxhyphen{}volume data processing

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Monitoring and logging} \sphinxhyphen{} Comprehensive system monitoring

\end{itemize}


\subsection{Technology Stack}
\label{\detokenize{Temp/architecture-options:technology-stack}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Python} \sphinxhyphen{} Core processing logic

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Bash} \sphinxhyphen{} System administration and automation

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{PHP} \sphinxhyphen{} Web interface components

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{DICOM toolkit} \sphinxhyphen{} Medical image handling

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{REDCap} \sphinxhyphen{} Transfer request management

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Docker} \sphinxhyphen{} Containerized processing components

\end{itemize}


\subsection{Deployment Model}
\label{\detokenize{Temp/architecture-options:deployment-model}}
\sphinxAtStartPar
FIONA is typically deployed as:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Single\sphinxhyphen{}server installation} \sphinxhyphen{} All components on one machine

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Processing user account} \sphinxhyphen{} Dedicated system user for operations

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Service\sphinxhyphen{}based architecture} \sphinxhyphen{} Daemon processes for continuous operation

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Cron\sphinxhyphen{}based scheduling} \sphinxhyphen{} Automated task execution

\end{itemize}

\sphinxAtStartPar
Such an architecture ensures reliable, automated processing of medical image data while maintaining compliance with research and privacy requirements.


\chapter{Contact Information}
\label{\detokenize{index:contact-information}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Website: \sphinxurl{https://fiona.ihelse.net}

\item {} 
\sphinxAtStartPar
Location: Haukeland University Hospital, Bergen, Norway

\end{itemize}


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\DUrole{xref}{\DUrole{std}{\DUrole{std-ref}{genindex}}}

\item {} 
\sphinxAtStartPar
\DUrole{xref}{\DUrole{std}{\DUrole{std-ref}{modindex}}}

\item {} 
\sphinxAtStartPar
\DUrole{xref}{\DUrole{std}{\DUrole{std-ref}{search}}}

\end{itemize}



\renewcommand{\indexname}{Index}
\printindex
\end{document}